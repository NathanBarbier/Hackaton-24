{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_athletes = pd.read_json(\"Data_Brut/olympic_athletes.json\")\n",
    "df_result= pd.read_html('Data_Brut/olympic_results.html')[0]\n",
    "df_medal = pd.read_excel('Data_Brut/olympic_medals.xlsx')\n",
    "df_host=pd.read_xml('Data_Brut/olympic_hosts.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>games_participations</th>\n",
       "      <th>first_game</th>\n",
       "      <th>athlete_year_birth</th>\n",
       "      <th>athlete_medals</th>\n",
       "      <th>bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://olympics.com/en/athletes/cooper-woods-...</td>\n",
       "      <td>Cooper WOODS-TOPALOVIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://olympics.com/en/athletes/elofsson</td>\n",
       "      <td>Felix ELOFSSON</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://olympics.com/en/athletes/dylan-walczyk</td>\n",
       "      <td>Dylan WALCZYK</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://olympics.com/en/athletes/olli-penttala</td>\n",
       "      <td>Olli PENTTALA</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://olympics.com/en/athletes/reikherd</td>\n",
       "      <td>Dmitriy REIKHERD</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         athlete_url       athlete_full_name  \\\n",
       "0  https://olympics.com/en/athletes/cooper-woods-...  Cooper WOODS-TOPALOVIC   \n",
       "1          https://olympics.com/en/athletes/elofsson          Felix ELOFSSON   \n",
       "2     https://olympics.com/en/athletes/dylan-walczyk           Dylan WALCZYK   \n",
       "3     https://olympics.com/en/athletes/olli-penttala           Olli PENTTALA   \n",
       "4          https://olympics.com/en/athletes/reikherd        Dmitriy REIKHERD   \n",
       "\n",
       "   games_participations        first_game  athlete_year_birth athlete_medals  \\\n",
       "0                     1      Beijing 2022              2000.0           None   \n",
       "1                     2  PyeongChang 2018              1995.0           None   \n",
       "2                     1      Beijing 2022              1993.0           None   \n",
       "3                     1      Beijing 2022              1995.0           None   \n",
       "4                     1      Beijing 2022              1989.0           None   \n",
       "\n",
       "    bio  \n",
       "0  None  \n",
       "1  None  \n",
       "2  None  \n",
       "3  None  \n",
       "4  None  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_athletes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de ligne du dataframe: 75904\n",
      "athlete_url                 0\n",
      "athlete_full_name           0\n",
      "games_participations        0\n",
      "first_game                 22\n",
      "athlete_year_birth       2456\n",
      "athlete_medals          60552\n",
      "bio                     53062\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de ligne du dataframe:\", len(df_athletes))\n",
    "print(df_athletes.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '\\n\\n\\n1\\n\\nS\\n\\n', '\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n', '\\n\\n\\n1\\n\\nG\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n1\\n\\nB\\n\\n', '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n', '\\n\\n\\n2\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nB\\n\\n', '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n', '\\n\\n\\n1\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n5\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n', '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n', '\\n\\n\\n2\\n\\nG\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n', '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nB\\n\\n', '\\n\\n\\n2\\n\\nS\\n\\n', '\\n\\n\\n3\\n\\nG\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n2\\n\\nB\\n\\n', '\\n\\n\\n4\\n\\nG\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n1\\n\\nB\\n\\n', '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n', '\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n', '\\n\\n\\n2\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n6\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n', '\\n\\n\\n2\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n', '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n', '\\n\\n\\n5\\n\\nG\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n', '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n', '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n', '\\n\\n\\n7\\n\\nG\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n', '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n', '\\n\\n\\n3\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n8\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n', '\\n\\n\\n4\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n8\\n\\nG\\n\\n', '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n23\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n8\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n1\\n\\nB\\n\\n', '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n5\\n\\nB\\n\\n', '\\n\\n\\n5\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n4\\n\\nB\\n\\n', '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nS\\n\\n\\n\\n6\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n8\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n6\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n5\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nS\\n\\n\\n\\n6\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n', '\\n\\n\\n6\\n\\nG\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n4\\n\\nB\\n\\n', '\\n\\n\\n8\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n6\\n\\nB\\n\\n', '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n9\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n', '\\n\\n\\n4\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n8\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n6\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n', '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n6\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n9\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n', '\\n\\n\\n5\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n', '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n5\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n9\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n7\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n5\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n2\\n\\nG\\n\\n\\n\\n1\\n\\nS\\n\\n\\n\\n6\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n4\\n\\nG\\n\\n\\n\\n2\\n\\nS\\n\\n\\n\\n1\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n9\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n', '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n3\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n1\\n\\nS\\n\\n\\n\\n4\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n',\n",
       "       '\\n\\n\\n3\\n\\nS\\n\\n\\n\\n3\\n\\nB\\n\\n', '\\n\\n\\n6\\n\\nG\\n\\n\\n\\n4\\n\\nS\\n\\n',\n",
       "       '\\n\\n\\n5\\n\\nS\\n\\n\\n\\n2\\n\\nB\\n\\n'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_athletes[\"athlete_medals\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_medal_info(value):\n",
    "    if pd.isna(value):\n",
    "        return value  \n",
    "    cleaned_value = re.sub(r'[^123456789SBG]', '', value)\n",
    "    return cleaned_value\n",
    "\n",
    "df_athletes['athlete_medals'] = df_athletes['athlete_medals'].apply(clean_medal_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>games_participations</th>\n",
       "      <th>first_game</th>\n",
       "      <th>athlete_year_birth</th>\n",
       "      <th>athlete_medals</th>\n",
       "      <th>bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://olympics.com/en/athletes/cooper-woods-...</td>\n",
       "      <td>Cooper WOODS-TOPALOVIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://olympics.com/en/athletes/elofsson</td>\n",
       "      <td>Felix ELOFSSON</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://olympics.com/en/athletes/dylan-walczyk</td>\n",
       "      <td>Dylan WALCZYK</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://olympics.com/en/athletes/olli-penttala</td>\n",
       "      <td>Olli PENTTALA</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://olympics.com/en/athletes/reikherd</td>\n",
       "      <td>Dmitriy REIKHERD</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://olympics.com/en/athletes/matt-graham</td>\n",
       "      <td>Matt GRAHAM</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1S</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://olympics.com/en/athletes/ikuma-horishima</td>\n",
       "      <td>Ikuma HORISHIMA</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1B</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://olympics.com/en/athletes/daichi-hara</td>\n",
       "      <td>Daichi HARA</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1B</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://olympics.com/en/athletes/laurent-dumais</td>\n",
       "      <td>Laurent DUMAIS</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://olympics.com/en/athletes/james-matheson</td>\n",
       "      <td>James MATHESON</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://olympics.com/en/athletes/pavel-kolmakov</td>\n",
       "      <td>Pavel KOLMAKOV</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://olympics.com/en/athletes/kosuke-sugimoto</td>\n",
       "      <td>Kosuke SUGIMOTO</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://olympics.com/en/athletes/brodie-summers</td>\n",
       "      <td>Brodie SUMMERS</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://olympics.com/en/athletes/severi-vierela</td>\n",
       "      <td>Severi VIERELA</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://olympics.com/en/athletes/marco-tade</td>\n",
       "      <td>Marco TADE</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://olympics.com/en/athletes/william-feneley</td>\n",
       "      <td>William FENELEY</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://olympics.com/en/athletes/mikael-kingsbury</td>\n",
       "      <td>Mikael KINGSBURY</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1G2S</td>\n",
       "      <td>\\n\\n\\nIn the period between his elite debut in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://olympics.com/en/athletes/so-matsuda</td>\n",
       "      <td>So MATSUDA</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://olympics.com/en/athletes/wallberg</td>\n",
       "      <td>Walter WALLBERG</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1G</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://olympics.com/en/athletes/bradley-wilson</td>\n",
       "      <td>Bradley WILSON</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>https://olympics.com/en/athletes/yang-zhao</td>\n",
       "      <td>Yang ZHAO</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://olympics.com/en/athletes/benjamin-cavet</td>\n",
       "      <td>Benjamin CAVET</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://olympics.com/en/athletes/cole-mcdonald</td>\n",
       "      <td>Cole MCDONALD</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>https://olympics.com/en/athletes/nick-page</td>\n",
       "      <td>Nick PAGE</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>https://olympics.com/en/athletes/sacha-theocharis</td>\n",
       "      <td>Sacha THEOCHARIS</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>https://olympics.com/en/athletes/jimi-salonen</td>\n",
       "      <td>Jimi SALONEN</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>https://olympics.com/en/athletes/nikita-novitskii</td>\n",
       "      <td>Nikita NOVITSKII</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://olympics.com/en/athletes/nikita-andreev</td>\n",
       "      <td>Nikita ANDREEV</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://olympics.com/en/athletes/ludvig-fjalls...</td>\n",
       "      <td>Ludvig FJALLSTROM</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://olympics.com/en/athletes/oskar-elofsson</td>\n",
       "      <td>Oskar ELOFSSON</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://olympics.com/en/athletes/bingqiang-mao</td>\n",
       "      <td>Bingqiang MAO</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https://olympics.com/en/athletes/kevin-rolland</td>\n",
       "      <td>Kevin ROLLAND</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1B</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://olympics.com/en/athletes/noah-bowman</td>\n",
       "      <td>Noah BOWMAN</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://olympics.com/en/athletes/robin-briguet</td>\n",
       "      <td>Robin BRIGUET</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>https://olympics.com/en/athletes/nico-porteous</td>\n",
       "      <td>Nico PORTEOUS</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1G1B</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>https://olympics.com/en/athletes/seung-hun-lee</td>\n",
       "      <td>Seung Hun LEE</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https://olympics.com/en/athletes/david-wise</td>\n",
       "      <td>David WISE</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2G1S</td>\n",
       "      <td>\\n\\n\\nThe favourite heading into the inaugural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://olympics.com/en/athletes/aaron-blunck</td>\n",
       "      <td>Aaron BLUNCK</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>https://olympics.com/en/athletes/brendan-mackay</td>\n",
       "      <td>Brendan MACKAY</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>https://olympics.com/en/athletes/ben-harrington</td>\n",
       "      <td>Ben HARRINGTON</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>https://olympics.com/en/athletes/sun-jingbo</td>\n",
       "      <td>Jingbo SUN</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://olympics.com/en/athletes/alex-ferreira</td>\n",
       "      <td>Alex FERREIRA</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1S1B</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>https://olympics.com/en/athletes/miguel-porteous</td>\n",
       "      <td>Miguel PORTEOUS</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>https://olympics.com/en/athletes/brendan-newby</td>\n",
       "      <td>Brendan NEWBY</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>https://olympics.com/en/athletes/gus-kenworthy</td>\n",
       "      <td>Gus KENWORTHY</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1S</td>\n",
       "      <td>\\n\\n\\nAFP World Championships overall titles i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>https://olympics.com/en/athletes/gustav-legnavsky</td>\n",
       "      <td>Gustav LEGNAVSKY</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://olympics.com/en/athletes/haizhuo-wang</td>\n",
       "      <td>Haizhuo WANG</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>https://olympics.com/en/athletes/marco-ladner</td>\n",
       "      <td>Marco LADNER</td>\n",
       "      <td>3</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>https://olympics.com/en/athletes/binghan-he</td>\n",
       "      <td>Binghan HE</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://olympics.com/en/athletes/birk-irving</td>\n",
       "      <td>Birk IRVING</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>https://olympics.com/en/athletes/simon-d-artois</td>\n",
       "      <td>Simon D ARTOIS</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>https://olympics.com/en/athletes/rafael-kreien...</td>\n",
       "      <td>Rafael KREIENBUEHL</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>https://olympics.com/en/athletes/jon-sallinen</td>\n",
       "      <td>Jon SALLINEN</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>https://olympics.com/en/athletes/edouard-therr...</td>\n",
       "      <td>Edouard THERRIAULT</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>https://olympics.com/en/athletes/matej-svancer</td>\n",
       "      <td>Matej SVANCER</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>https://olympics.com/en/athletes/teal-harle</td>\n",
       "      <td>Teal HARLE</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>https://olympics.com/en/athletes/colin-wili</td>\n",
       "      <td>Colin WILI</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>https://olympics.com/en/athletes/hugo-burvall</td>\n",
       "      <td>Hugo BURVALL</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>https://olympics.com/en/athletes/leonardo-dona...</td>\n",
       "      <td>Leonardo DONAGGIO</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>https://olympics.com/en/athletes/birk-ruud</td>\n",
       "      <td>Birk RUUD</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1G</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          athlete_url       athlete_full_name  \\\n",
       "0   https://olympics.com/en/athletes/cooper-woods-...  Cooper WOODS-TOPALOVIC   \n",
       "1           https://olympics.com/en/athletes/elofsson          Felix ELOFSSON   \n",
       "2      https://olympics.com/en/athletes/dylan-walczyk           Dylan WALCZYK   \n",
       "3      https://olympics.com/en/athletes/olli-penttala           Olli PENTTALA   \n",
       "4           https://olympics.com/en/athletes/reikherd        Dmitriy REIKHERD   \n",
       "5        https://olympics.com/en/athletes/matt-graham             Matt GRAHAM   \n",
       "6    https://olympics.com/en/athletes/ikuma-horishima         Ikuma HORISHIMA   \n",
       "7        https://olympics.com/en/athletes/daichi-hara             Daichi HARA   \n",
       "8     https://olympics.com/en/athletes/laurent-dumais          Laurent DUMAIS   \n",
       "9     https://olympics.com/en/athletes/james-matheson          James MATHESON   \n",
       "10    https://olympics.com/en/athletes/pavel-kolmakov          Pavel KOLMAKOV   \n",
       "11   https://olympics.com/en/athletes/kosuke-sugimoto         Kosuke SUGIMOTO   \n",
       "12    https://olympics.com/en/athletes/brodie-summers          Brodie SUMMERS   \n",
       "13    https://olympics.com/en/athletes/severi-vierela          Severi VIERELA   \n",
       "14        https://olympics.com/en/athletes/marco-tade              Marco TADE   \n",
       "15   https://olympics.com/en/athletes/william-feneley         William FENELEY   \n",
       "16  https://olympics.com/en/athletes/mikael-kingsbury        Mikael KINGSBURY   \n",
       "17        https://olympics.com/en/athletes/so-matsuda              So MATSUDA   \n",
       "18          https://olympics.com/en/athletes/wallberg         Walter WALLBERG   \n",
       "19    https://olympics.com/en/athletes/bradley-wilson          Bradley WILSON   \n",
       "20         https://olympics.com/en/athletes/yang-zhao               Yang ZHAO   \n",
       "21    https://olympics.com/en/athletes/benjamin-cavet          Benjamin CAVET   \n",
       "22     https://olympics.com/en/athletes/cole-mcdonald           Cole MCDONALD   \n",
       "23         https://olympics.com/en/athletes/nick-page               Nick PAGE   \n",
       "24  https://olympics.com/en/athletes/sacha-theocharis        Sacha THEOCHARIS   \n",
       "25      https://olympics.com/en/athletes/jimi-salonen            Jimi SALONEN   \n",
       "26  https://olympics.com/en/athletes/nikita-novitskii        Nikita NOVITSKII   \n",
       "27    https://olympics.com/en/athletes/nikita-andreev          Nikita ANDREEV   \n",
       "28  https://olympics.com/en/athletes/ludvig-fjalls...       Ludvig FJALLSTROM   \n",
       "29    https://olympics.com/en/athletes/oskar-elofsson          Oskar ELOFSSON   \n",
       "30     https://olympics.com/en/athletes/bingqiang-mao           Bingqiang MAO   \n",
       "31     https://olympics.com/en/athletes/kevin-rolland           Kevin ROLLAND   \n",
       "32       https://olympics.com/en/athletes/noah-bowman             Noah BOWMAN   \n",
       "33     https://olympics.com/en/athletes/robin-briguet           Robin BRIGUET   \n",
       "34     https://olympics.com/en/athletes/nico-porteous           Nico PORTEOUS   \n",
       "35     https://olympics.com/en/athletes/seung-hun-lee           Seung Hun LEE   \n",
       "36        https://olympics.com/en/athletes/david-wise              David WISE   \n",
       "37      https://olympics.com/en/athletes/aaron-blunck            Aaron BLUNCK   \n",
       "38    https://olympics.com/en/athletes/brendan-mackay          Brendan MACKAY   \n",
       "39    https://olympics.com/en/athletes/ben-harrington          Ben HARRINGTON   \n",
       "40        https://olympics.com/en/athletes/sun-jingbo              Jingbo SUN   \n",
       "41     https://olympics.com/en/athletes/alex-ferreira           Alex FERREIRA   \n",
       "42   https://olympics.com/en/athletes/miguel-porteous         Miguel PORTEOUS   \n",
       "43     https://olympics.com/en/athletes/brendan-newby           Brendan NEWBY   \n",
       "44     https://olympics.com/en/athletes/gus-kenworthy           Gus KENWORTHY   \n",
       "45  https://olympics.com/en/athletes/gustav-legnavsky        Gustav LEGNAVSKY   \n",
       "46      https://olympics.com/en/athletes/haizhuo-wang            Haizhuo WANG   \n",
       "47      https://olympics.com/en/athletes/marco-ladner            Marco LADNER   \n",
       "48        https://olympics.com/en/athletes/binghan-he              Binghan HE   \n",
       "49       https://olympics.com/en/athletes/birk-irving             Birk IRVING   \n",
       "50    https://olympics.com/en/athletes/simon-d-artois          Simon D ARTOIS   \n",
       "51  https://olympics.com/en/athletes/rafael-kreien...      Rafael KREIENBUEHL   \n",
       "52      https://olympics.com/en/athletes/jon-sallinen            Jon SALLINEN   \n",
       "53  https://olympics.com/en/athletes/edouard-therr...      Edouard THERRIAULT   \n",
       "54     https://olympics.com/en/athletes/matej-svancer           Matej SVANCER   \n",
       "55        https://olympics.com/en/athletes/teal-harle              Teal HARLE   \n",
       "56        https://olympics.com/en/athletes/colin-wili              Colin WILI   \n",
       "57      https://olympics.com/en/athletes/hugo-burvall            Hugo BURVALL   \n",
       "58  https://olympics.com/en/athletes/leonardo-dona...       Leonardo DONAGGIO   \n",
       "59         https://olympics.com/en/athletes/birk-ruud               Birk RUUD   \n",
       "\n",
       "    games_participations        first_game  athlete_year_birth athlete_medals  \\\n",
       "0                      1      Beijing 2022              2000.0           None   \n",
       "1                      2  PyeongChang 2018              1995.0           None   \n",
       "2                      1      Beijing 2022              1993.0           None   \n",
       "3                      1      Beijing 2022              1995.0           None   \n",
       "4                      1      Beijing 2022              1989.0           None   \n",
       "5                      3        Sochi 2014              1994.0             1S   \n",
       "6                      2  PyeongChang 2018              1997.0             1B   \n",
       "7                      2  PyeongChang 2018              1997.0             1B   \n",
       "8                      1      Beijing 2022              1996.0           None   \n",
       "9                      2  PyeongChang 2018              1995.0           None   \n",
       "10                     3        Sochi 2014              1996.0           None   \n",
       "11                     1      Beijing 2022              1994.0           None   \n",
       "12                     3        Sochi 2014              1993.0           None   \n",
       "13                     1      Beijing 2022              2001.0           None   \n",
       "14                     1      Beijing 2022              1995.0           None   \n",
       "15                     1      Beijing 2022              1999.0           None   \n",
       "16                     3        Sochi 2014              1992.0           1G2S   \n",
       "17                     1      Beijing 2022              1999.0           None   \n",
       "18                     2  PyeongChang 2018              2000.0             1G   \n",
       "19                     3        Sochi 2014              1992.0           None   \n",
       "20                     1      Beijing 2022              1992.0           None   \n",
       "21                     3        Sochi 2014              1994.0           None   \n",
       "22                     1      Beijing 2022              2003.0           None   \n",
       "23                     1      Beijing 2022              2002.0           None   \n",
       "24                     2  PyeongChang 2018              1990.0           None   \n",
       "25                     3        Sochi 2014              1994.0           None   \n",
       "26                     1      Beijing 2022              2000.0           None   \n",
       "27                     1      Beijing 2022              2004.0           None   \n",
       "28                     3        Sochi 2014              1993.0           None   \n",
       "29                     1      Beijing 2022              1998.0           None   \n",
       "30                     2  PyeongChang 2018              2001.0           None   \n",
       "31                     3        Sochi 2014              1989.0             1B   \n",
       "32                     3        Sochi 2014              1992.0           None   \n",
       "33                     2  PyeongChang 2018              1999.0           None   \n",
       "34                     2  PyeongChang 2018              2001.0           1G1B   \n",
       "35                     1      Beijing 2022              2005.0           None   \n",
       "36                     3        Sochi 2014              1990.0           2G1S   \n",
       "37                     3        Sochi 2014              1996.0           None   \n",
       "38                     1      Beijing 2022              1997.0           None   \n",
       "39                     1      Beijing 2022              2001.0           None   \n",
       "40                     1      Beijing 2022              2003.0           None   \n",
       "41                     2  PyeongChang 2018              1994.0           1S1B   \n",
       "42                     2  PyeongChang 2018              1999.0           None   \n",
       "43                     2  PyeongChang 2018              1996.0           None   \n",
       "44                     3        Sochi 2014              1991.0             1S   \n",
       "45                     1      Beijing 2022              2005.0           None   \n",
       "46                     1      Beijing 2022              2003.0           None   \n",
       "47                     3        Sochi 2014              1998.0           None   \n",
       "48                     1      Beijing 2022              2003.0           None   \n",
       "49                     1      Beijing 2022              1999.0           None   \n",
       "50                     1      Beijing 2022              1992.0           None   \n",
       "51                     2  PyeongChang 2018              1999.0           None   \n",
       "52                     1      Beijing 2022              2000.0           None   \n",
       "53                     1      Beijing 2022              2003.0           None   \n",
       "54                     1      Beijing 2022              2004.0           None   \n",
       "55                     2  PyeongChang 2018              1996.0           None   \n",
       "56                     1      Beijing 2022              1998.0           None   \n",
       "57                     1      Beijing 2022              1997.0           None   \n",
       "58                     1      Beijing 2022              2003.0           None   \n",
       "59                     1      Beijing 2022              2000.0             1G   \n",
       "\n",
       "                                                  bio  \n",
       "0                                                None  \n",
       "1                                                None  \n",
       "2                                                None  \n",
       "3                                                None  \n",
       "4                                                None  \n",
       "5                                                None  \n",
       "6                                                None  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9                                                None  \n",
       "10                                               None  \n",
       "11                                               None  \n",
       "12                                               None  \n",
       "13                                               None  \n",
       "14                                               None  \n",
       "15                                               None  \n",
       "16  \\n\\n\\nIn the period between his elite debut in...  \n",
       "17                                               None  \n",
       "18                                               None  \n",
       "19                                               None  \n",
       "20                                               None  \n",
       "21                                               None  \n",
       "22                                               None  \n",
       "23                                               None  \n",
       "24                                               None  \n",
       "25                                               None  \n",
       "26                                               None  \n",
       "27                                               None  \n",
       "28                                               None  \n",
       "29                                               None  \n",
       "30                                               None  \n",
       "31                                               None  \n",
       "32                                               None  \n",
       "33                                               None  \n",
       "34                                               None  \n",
       "35                                               None  \n",
       "36  \\n\\n\\nThe favourite heading into the inaugural...  \n",
       "37                                               None  \n",
       "38                                               None  \n",
       "39                                               None  \n",
       "40                                               None  \n",
       "41                                               None  \n",
       "42                                               None  \n",
       "43                                               None  \n",
       "44  \\n\\n\\nAFP World Championships overall titles i...  \n",
       "45                                               None  \n",
       "46                                               None  \n",
       "47                                               None  \n",
       "48                                               None  \n",
       "49                                               None  \n",
       "50                                               None  \n",
       "51                                               None  \n",
       "52                                               None  \n",
       "53                                               None  \n",
       "54                                               None  \n",
       "55                                               None  \n",
       "56                                               None  \n",
       "57                                               None  \n",
       "58                                               None  \n",
       "59                                               None  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_athletes.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_medals(value):\n",
    "    if pd.isna(value):\n",
    "        return {'M_gold': 0, 'M_silver': 0, 'M_bronze': 0}\n",
    "    \n",
    "    gold = re.search(r'(\\d+)G', value)\n",
    "    silver = re.search(r'(\\d+)S', value)\n",
    "    bronze = re.search(r'(\\d+)B', value)\n",
    "    \n",
    "    return {\n",
    "        'M_gold': int(gold.group(1)) if gold else 0,\n",
    "        'M_silver': int(silver.group(1)) if silver else 0,\n",
    "        'M_bronze': int(bronze.group(1)) if bronze else 0\n",
    "    }\n",
    "\n",
    "medal_counts = df_athletes['athlete_medals'].apply(extract_medals)\n",
    "\n",
    "medal_counts_df = pd.DataFrame(medal_counts.tolist())\n",
    "df_athletes = pd.concat([df_athletes, medal_counts_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>games_participations</th>\n",
       "      <th>first_game</th>\n",
       "      <th>athlete_year_birth</th>\n",
       "      <th>athlete_medals</th>\n",
       "      <th>bio</th>\n",
       "      <th>M_gold</th>\n",
       "      <th>M_silver</th>\n",
       "      <th>M_bronze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://olympics.com/en/athletes/cooper-woods-...</td>\n",
       "      <td>Cooper WOODS-TOPALOVIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://olympics.com/en/athletes/elofsson</td>\n",
       "      <td>Felix ELOFSSON</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://olympics.com/en/athletes/dylan-walczyk</td>\n",
       "      <td>Dylan WALCZYK</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://olympics.com/en/athletes/olli-penttala</td>\n",
       "      <td>Olli PENTTALA</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://olympics.com/en/athletes/reikherd</td>\n",
       "      <td>Dmitriy REIKHERD</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         athlete_url       athlete_full_name  \\\n",
       "0  https://olympics.com/en/athletes/cooper-woods-...  Cooper WOODS-TOPALOVIC   \n",
       "1          https://olympics.com/en/athletes/elofsson          Felix ELOFSSON   \n",
       "2     https://olympics.com/en/athletes/dylan-walczyk           Dylan WALCZYK   \n",
       "3     https://olympics.com/en/athletes/olli-penttala           Olli PENTTALA   \n",
       "4          https://olympics.com/en/athletes/reikherd        Dmitriy REIKHERD   \n",
       "\n",
       "   games_participations        first_game  athlete_year_birth athlete_medals  \\\n",
       "0                     1      Beijing 2022              2000.0           None   \n",
       "1                     2  PyeongChang 2018              1995.0           None   \n",
       "2                     1      Beijing 2022              1993.0           None   \n",
       "3                     1      Beijing 2022              1995.0           None   \n",
       "4                     1      Beijing 2022              1989.0           None   \n",
       "\n",
       "    bio  M_gold  M_silver  M_bronze  \n",
       "0  None       0         0         0  \n",
       "1  None       0         0         0  \n",
       "2  None       0         0         0  \n",
       "3  None       0         0         0  \n",
       "4  None       0         0         0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_athletes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athlete_url                 0\n",
      "athlete_full_name           0\n",
      "games_participations        0\n",
      "first_game                 22\n",
      "athlete_year_birth       2456\n",
      "athlete_medals          60552\n",
      "M_gold                      0\n",
      "M_silver                    0\n",
      "M_bronze                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_athletes = df_athletes.drop(\"bio\",axis=1)\n",
    "print(df_athletes.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_athletes = df_athletes.drop(\"athlete_medals\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>games_participations</th>\n",
       "      <th>first_game</th>\n",
       "      <th>athlete_year_birth</th>\n",
       "      <th>M_gold</th>\n",
       "      <th>M_silver</th>\n",
       "      <th>M_bronze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://olympics.com/en/athletes/cooper-woods-...</td>\n",
       "      <td>Cooper WOODS-TOPALOVIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://olympics.com/en/athletes/elofsson</td>\n",
       "      <td>Felix ELOFSSON</td>\n",
       "      <td>2</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://olympics.com/en/athletes/dylan-walczyk</td>\n",
       "      <td>Dylan WALCZYK</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://olympics.com/en/athletes/olli-penttala</td>\n",
       "      <td>Olli PENTTALA</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://olympics.com/en/athletes/reikherd</td>\n",
       "      <td>Dmitriy REIKHERD</td>\n",
       "      <td>1</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         athlete_url       athlete_full_name  \\\n",
       "0  https://olympics.com/en/athletes/cooper-woods-...  Cooper WOODS-TOPALOVIC   \n",
       "1          https://olympics.com/en/athletes/elofsson          Felix ELOFSSON   \n",
       "2     https://olympics.com/en/athletes/dylan-walczyk           Dylan WALCZYK   \n",
       "3     https://olympics.com/en/athletes/olli-penttala           Olli PENTTALA   \n",
       "4          https://olympics.com/en/athletes/reikherd        Dmitriy REIKHERD   \n",
       "\n",
       "   games_participations        first_game  athlete_year_birth  M_gold  \\\n",
       "0                     1      Beijing 2022              2000.0       0   \n",
       "1                     2  PyeongChang 2018              1995.0       0   \n",
       "2                     1      Beijing 2022              1993.0       0   \n",
       "3                     1      Beijing 2022              1995.0       0   \n",
       "4                     1      Beijing 2022              1989.0       0   \n",
       "\n",
       "   M_silver  M_bronze  \n",
       "0         0         0  \n",
       "1         0         0  \n",
       "2         0         0  \n",
       "3         0         0  \n",
       "4         0         0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_athletes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_athletes['total_medals'] = df_athletes['M_gold'] + df_athletes['M_silver'] + df_athletes['M_bronze']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>event_title</th>\n",
       "      <th>slug_game</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>athletes</th>\n",
       "      <th>rank_equal</th>\n",
       "      <th>rank_position</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>value_unit</th>\n",
       "      <th>value_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>[('Stefania CONSTANTINI', 'https://olympics.co...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>[('Kristin SKASLIEN', 'https://olympics.com/en...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>BRONZE</td>\n",
       "      <td>[('Almida DE VAL', 'https://olympics.com/en/at...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SE</td>\n",
       "      <td>SWE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[('Jennifer DODDS', 'https://olympics.com/en/a...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[('Rachel HOMAN', 'https://olympics.com/en/ath...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>CAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 discipline_title    event_title     slug_game participant_type  \\\n",
       "0           0          Curling  Mixed Doubles  beijing-2022         GameTeam   \n",
       "1           1          Curling  Mixed Doubles  beijing-2022         GameTeam   \n",
       "2           2          Curling  Mixed Doubles  beijing-2022         GameTeam   \n",
       "3           3          Curling  Mixed Doubles  beijing-2022         GameTeam   \n",
       "4           4          Curling  Mixed Doubles  beijing-2022         GameTeam   \n",
       "\n",
       "  medal_type                                           athletes rank_equal  \\\n",
       "0       GOLD  [('Stefania CONSTANTINI', 'https://olympics.co...      False   \n",
       "1     SILVER  [('Kristin SKASLIEN', 'https://olympics.com/en...      False   \n",
       "2     BRONZE  [('Almida DE VAL', 'https://olympics.com/en/at...      False   \n",
       "3        NaN  [('Jennifer DODDS', 'https://olympics.com/en/a...      False   \n",
       "4        NaN  [('Rachel HOMAN', 'https://olympics.com/en/ath...      False   \n",
       "\n",
       "  rank_position   country_name country_code country_3_letter_code athlete_url  \\\n",
       "0             1          Italy           IT                   ITA         NaN   \n",
       "1             2         Norway           NO                   NOR         NaN   \n",
       "2             3         Sweden           SE                   SWE         NaN   \n",
       "3             4  Great Britain           GB                   GBR         NaN   \n",
       "4             5         Canada           CA                   CAN         NaN   \n",
       "\n",
       "  athlete_full_name value_unit value_type  \n",
       "0               NaN        NaN        NaN  \n",
       "1               NaN        NaN        NaN  \n",
       "2               NaN        NaN        NaN  \n",
       "3               NaN        NaN        NaN  \n",
       "4               NaN        NaN        NaN  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_result.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>event_title</th>\n",
       "      <th>slug_game</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>athletes</th>\n",
       "      <th>rank_equal</th>\n",
       "      <th>rank_position</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>value_unit</th>\n",
       "      <th>value_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>[('Stefania CONSTANTINI', 'https://olympics.co...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>[('Kristin SKASLIEN', 'https://olympics.com/en...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>BRONZE</td>\n",
       "      <td>[('Almida DE VAL', 'https://olympics.com/en/at...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SE</td>\n",
       "      <td>SWE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[('Jennifer DODDS', 'https://olympics.com/en/a...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[('Rachel HOMAN', 'https://olympics.com/en/ath...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>CAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  discipline_title    event_title     slug_game participant_type medal_type  \\\n",
       "0          Curling  Mixed Doubles  beijing-2022         GameTeam       GOLD   \n",
       "1          Curling  Mixed Doubles  beijing-2022         GameTeam     SILVER   \n",
       "2          Curling  Mixed Doubles  beijing-2022         GameTeam     BRONZE   \n",
       "3          Curling  Mixed Doubles  beijing-2022         GameTeam        NaN   \n",
       "4          Curling  Mixed Doubles  beijing-2022         GameTeam        NaN   \n",
       "\n",
       "                                            athletes rank_equal rank_position  \\\n",
       "0  [('Stefania CONSTANTINI', 'https://olympics.co...      False             1   \n",
       "1  [('Kristin SKASLIEN', 'https://olympics.com/en...      False             2   \n",
       "2  [('Almida DE VAL', 'https://olympics.com/en/at...      False             3   \n",
       "3  [('Jennifer DODDS', 'https://olympics.com/en/a...      False             4   \n",
       "4  [('Rachel HOMAN', 'https://olympics.com/en/ath...      False             5   \n",
       "\n",
       "    country_name country_code country_3_letter_code athlete_url  \\\n",
       "0          Italy           IT                   ITA         NaN   \n",
       "1         Norway           NO                   NOR         NaN   \n",
       "2         Sweden           SE                   SWE         NaN   \n",
       "3  Great Britain           GB                   GBR         NaN   \n",
       "4         Canada           CA                   CAN         NaN   \n",
       "\n",
       "  athlete_full_name value_unit value_type  \n",
       "0               NaN        NaN        NaN  \n",
       "1               NaN        NaN        NaN  \n",
       "2               NaN        NaN        NaN  \n",
       "3               NaN        NaN        NaN  \n",
       "4               NaN        NaN        NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_result.rename(columns={'slug_game': 'game_slug'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_result.drop(columns=[\"athletes\"])\n",
    "df_result=df_result.drop(columns=[\"athlete_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>slug_game</th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_gender</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>participant_title</th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Italy</td>\n",
       "      <td>https://olympics.com/en/athletes/stefania-cons...</td>\n",
       "      <td>Stefania CONSTANTINI</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Italy</td>\n",
       "      <td>https://olympics.com/en/athletes/amos-mosaner</td>\n",
       "      <td>Amos MOSANER</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Norway</td>\n",
       "      <td>https://olympics.com/en/athletes/kristin-skaslien</td>\n",
       "      <td>Kristin SKASLIEN</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Norway</td>\n",
       "      <td>https://olympics.com/en/athletes/magnus-nedreg...</td>\n",
       "      <td>Magnus NEDREGOTTEN</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>BRONZE</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>https://olympics.com/en/athletes/almida-de-val</td>\n",
       "      <td>Almida DE VAL</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SE</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 discipline_title     slug_game    event_title event_gender  \\\n",
       "0           0          Curling  beijing-2022  Mixed Doubles        Mixed   \n",
       "1           1          Curling  beijing-2022  Mixed Doubles        Mixed   \n",
       "2           2          Curling  beijing-2022  Mixed Doubles        Mixed   \n",
       "3           3          Curling  beijing-2022  Mixed Doubles        Mixed   \n",
       "4           4          Curling  beijing-2022  Mixed Doubles        Mixed   \n",
       "\n",
       "  medal_type participant_type participant_title  \\\n",
       "0       GOLD         GameTeam             Italy   \n",
       "1       GOLD         GameTeam             Italy   \n",
       "2     SILVER         GameTeam            Norway   \n",
       "3     SILVER         GameTeam            Norway   \n",
       "4     BRONZE         GameTeam            Sweden   \n",
       "\n",
       "                                         athlete_url     athlete_full_name  \\\n",
       "0  https://olympics.com/en/athletes/stefania-cons...  Stefania CONSTANTINI   \n",
       "1      https://olympics.com/en/athletes/amos-mosaner          Amos MOSANER   \n",
       "2  https://olympics.com/en/athletes/kristin-skaslien      Kristin SKASLIEN   \n",
       "3  https://olympics.com/en/athletes/magnus-nedreg...    Magnus NEDREGOTTEN   \n",
       "4     https://olympics.com/en/athletes/almida-de-val         Almida DE VAL   \n",
       "\n",
       "  country_name country_code country_3_letter_code  \n",
       "0        Italy           IT                   ITA  \n",
       "1        Italy           IT                   ITA  \n",
       "2       Norway           NO                   NOR  \n",
       "3       Norway           NO                   NOR  \n",
       "4       Sweden           SE                   SWE  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medal=df_medal.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>slug_game</th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_gender</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>participant_title</th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Italy</td>\n",
       "      <td>https://olympics.com/en/athletes/stefania-cons...</td>\n",
       "      <td>Stefania CONSTANTINI</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Italy</td>\n",
       "      <td>https://olympics.com/en/athletes/amos-mosaner</td>\n",
       "      <td>Amos MOSANER</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Norway</td>\n",
       "      <td>https://olympics.com/en/athletes/kristin-skaslien</td>\n",
       "      <td>Kristin SKASLIEN</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Norway</td>\n",
       "      <td>https://olympics.com/en/athletes/magnus-nedreg...</td>\n",
       "      <td>Magnus NEDREGOTTEN</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>BRONZE</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>https://olympics.com/en/athletes/almida-de-val</td>\n",
       "      <td>Almida DE VAL</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SE</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  discipline_title     slug_game    event_title event_gender medal_type  \\\n",
       "0          Curling  beijing-2022  Mixed Doubles        Mixed       GOLD   \n",
       "1          Curling  beijing-2022  Mixed Doubles        Mixed       GOLD   \n",
       "2          Curling  beijing-2022  Mixed Doubles        Mixed     SILVER   \n",
       "3          Curling  beijing-2022  Mixed Doubles        Mixed     SILVER   \n",
       "4          Curling  beijing-2022  Mixed Doubles        Mixed     BRONZE   \n",
       "\n",
       "  participant_type participant_title  \\\n",
       "0         GameTeam             Italy   \n",
       "1         GameTeam             Italy   \n",
       "2         GameTeam            Norway   \n",
       "3         GameTeam            Norway   \n",
       "4         GameTeam            Sweden   \n",
       "\n",
       "                                         athlete_url     athlete_full_name  \\\n",
       "0  https://olympics.com/en/athletes/stefania-cons...  Stefania CONSTANTINI   \n",
       "1      https://olympics.com/en/athletes/amos-mosaner          Amos MOSANER   \n",
       "2  https://olympics.com/en/athletes/kristin-skaslien      Kristin SKASLIEN   \n",
       "3  https://olympics.com/en/athletes/magnus-nedreg...    Magnus NEDREGOTTEN   \n",
       "4     https://olympics.com/en/athletes/almida-de-val         Almida DE VAL   \n",
       "\n",
       "  country_name country_code country_3_letter_code  \n",
       "0        Italy           IT                   ITA  \n",
       "1        Italy           IT                   ITA  \n",
       "2       Norway           NO                   NOR  \n",
       "3       Norway           NO                   NOR  \n",
       "4       Sweden           SE                   SWE  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medal=df_medal.rename(columns={'slug_game': 'game_slug'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>game_slug</th>\n",
       "      <th>event_title</th>\n",
       "      <th>event_gender</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>participant_title</th>\n",
       "      <th>athlete_url</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Italy</td>\n",
       "      <td>https://olympics.com/en/athletes/stefania-cons...</td>\n",
       "      <td>Stefania CONSTANTINI</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Italy</td>\n",
       "      <td>https://olympics.com/en/athletes/amos-mosaner</td>\n",
       "      <td>Amos MOSANER</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Norway</td>\n",
       "      <td>https://olympics.com/en/athletes/kristin-skaslien</td>\n",
       "      <td>Kristin SKASLIEN</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Norway</td>\n",
       "      <td>https://olympics.com/en/athletes/magnus-nedreg...</td>\n",
       "      <td>Magnus NEDREGOTTEN</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Curling</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>BRONZE</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>https://olympics.com/en/athletes/almida-de-val</td>\n",
       "      <td>Almida DE VAL</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SE</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  discipline_title     game_slug    event_title event_gender medal_type  \\\n",
       "0          Curling  beijing-2022  Mixed Doubles        Mixed       GOLD   \n",
       "1          Curling  beijing-2022  Mixed Doubles        Mixed       GOLD   \n",
       "2          Curling  beijing-2022  Mixed Doubles        Mixed     SILVER   \n",
       "3          Curling  beijing-2022  Mixed Doubles        Mixed     SILVER   \n",
       "4          Curling  beijing-2022  Mixed Doubles        Mixed     BRONZE   \n",
       "\n",
       "  participant_type participant_title  \\\n",
       "0         GameTeam             Italy   \n",
       "1         GameTeam             Italy   \n",
       "2         GameTeam            Norway   \n",
       "3         GameTeam            Norway   \n",
       "4         GameTeam            Sweden   \n",
       "\n",
       "                                         athlete_url     athlete_full_name  \\\n",
       "0  https://olympics.com/en/athletes/stefania-cons...  Stefania CONSTANTINI   \n",
       "1      https://olympics.com/en/athletes/amos-mosaner          Amos MOSANER   \n",
       "2  https://olympics.com/en/athletes/kristin-skaslien      Kristin SKASLIEN   \n",
       "3  https://olympics.com/en/athletes/magnus-nedreg...    Magnus NEDREGOTTEN   \n",
       "4     https://olympics.com/en/athletes/almida-de-val         Almida DE VAL   \n",
       "\n",
       "  country_name country_code country_3_letter_code  \n",
       "0        Italy           IT                   ITA  \n",
       "1        Italy           IT                   ITA  \n",
       "2       Norway           NO                   NOR  \n",
       "3       Norway           NO                   NOR  \n",
       "4       Sweden           SE                   SWE  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de ligne du dataframe: 21697\n",
      "discipline_title             0\n",
      "game_slug                    0\n",
      "event_title                  0\n",
      "event_gender                 0\n",
      "medal_type                   0\n",
      "participant_type             0\n",
      "participant_title        15113\n",
      "athlete_url               4670\n",
      "athlete_full_name         3624\n",
      "country_name                 0\n",
      "country_code              1502\n",
      "country_3_letter_code        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de ligne du dataframe:\", len(df_medal))\n",
    "print(df_medal.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>game_slug</th>\n",
       "      <th>game_end_date</th>\n",
       "      <th>game_start_date</th>\n",
       "      <th>game_location</th>\n",
       "      <th>game_name</th>\n",
       "      <th>game_season</th>\n",
       "      <th>game_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>2022-02-20T12:00:00Z</td>\n",
       "      <td>2022-02-04T15:00:00Z</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tokyo-2020</td>\n",
       "      <td>2021-08-08T14:00:00Z</td>\n",
       "      <td>2021-07-23T11:00:00Z</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Tokyo 2020</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pyeongchang-2018</td>\n",
       "      <td>2018-02-25T08:00:00Z</td>\n",
       "      <td>2018-02-08T23:00:00Z</td>\n",
       "      <td>Republic of Korea</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rio-2016</td>\n",
       "      <td>2016-08-21T21:00:00Z</td>\n",
       "      <td>2016-08-05T12:00:00Z</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Rio 2016</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>sochi-2014</td>\n",
       "      <td>2014-02-23T16:00:00Z</td>\n",
       "      <td>2014-02-07T04:00:00Z</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         game_slug         game_end_date       game_start_date  \\\n",
       "0      0      beijing-2022  2022-02-20T12:00:00Z  2022-02-04T15:00:00Z   \n",
       "1      1        tokyo-2020  2021-08-08T14:00:00Z  2021-07-23T11:00:00Z   \n",
       "2      2  pyeongchang-2018  2018-02-25T08:00:00Z  2018-02-08T23:00:00Z   \n",
       "3      3          rio-2016  2016-08-21T21:00:00Z  2016-08-05T12:00:00Z   \n",
       "4      4        sochi-2014  2014-02-23T16:00:00Z  2014-02-07T04:00:00Z   \n",
       "\n",
       "        game_location         game_name game_season  game_year  \n",
       "0               China      Beijing 2022      Winter       2022  \n",
       "1               Japan        Tokyo 2020      Summer       2020  \n",
       "2   Republic of Korea  PyeongChang 2018      Winter       2018  \n",
       "3              Brazil          Rio 2016      Summer       2016  \n",
       "4  Russian Federation        Sochi 2014      Winter       2014  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_host.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_host=df_host.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_slug</th>\n",
       "      <th>game_end_date</th>\n",
       "      <th>game_start_date</th>\n",
       "      <th>game_location</th>\n",
       "      <th>game_name</th>\n",
       "      <th>game_season</th>\n",
       "      <th>game_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>2022-02-20T12:00:00Z</td>\n",
       "      <td>2022-02-04T15:00:00Z</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing 2022</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokyo-2020</td>\n",
       "      <td>2021-08-08T14:00:00Z</td>\n",
       "      <td>2021-07-23T11:00:00Z</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Tokyo 2020</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pyeongchang-2018</td>\n",
       "      <td>2018-02-25T08:00:00Z</td>\n",
       "      <td>2018-02-08T23:00:00Z</td>\n",
       "      <td>Republic of Korea</td>\n",
       "      <td>PyeongChang 2018</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rio-2016</td>\n",
       "      <td>2016-08-21T21:00:00Z</td>\n",
       "      <td>2016-08-05T12:00:00Z</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Rio 2016</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sochi-2014</td>\n",
       "      <td>2014-02-23T16:00:00Z</td>\n",
       "      <td>2014-02-07T04:00:00Z</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>Sochi 2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>london-2012</td>\n",
       "      <td>2012-08-12T19:00:00Z</td>\n",
       "      <td>2012-07-27T07:00:00Z</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>London 2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vancouver-2010</td>\n",
       "      <td>2010-02-28T04:00:00Z</td>\n",
       "      <td>2010-02-12T16:00:00Z</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Vancouver 2010</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>beijing-2008</td>\n",
       "      <td>2008-08-24T12:00:00Z</td>\n",
       "      <td>2008-08-08T00:00:00Z</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing 2008</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>turin-2006</td>\n",
       "      <td>2006-02-26T19:00:00Z</td>\n",
       "      <td>2006-02-10T07:00:00Z</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Turin 2006</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>athens-2004</td>\n",
       "      <td>2004-08-29T18:00:00Z</td>\n",
       "      <td>2004-08-13T06:00:00Z</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens 2004</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          game_slug         game_end_date       game_start_date  \\\n",
       "0      beijing-2022  2022-02-20T12:00:00Z  2022-02-04T15:00:00Z   \n",
       "1        tokyo-2020  2021-08-08T14:00:00Z  2021-07-23T11:00:00Z   \n",
       "2  pyeongchang-2018  2018-02-25T08:00:00Z  2018-02-08T23:00:00Z   \n",
       "3          rio-2016  2016-08-21T21:00:00Z  2016-08-05T12:00:00Z   \n",
       "4        sochi-2014  2014-02-23T16:00:00Z  2014-02-07T04:00:00Z   \n",
       "5       london-2012  2012-08-12T19:00:00Z  2012-07-27T07:00:00Z   \n",
       "6    vancouver-2010  2010-02-28T04:00:00Z  2010-02-12T16:00:00Z   \n",
       "7      beijing-2008  2008-08-24T12:00:00Z  2008-08-08T00:00:00Z   \n",
       "8        turin-2006  2006-02-26T19:00:00Z  2006-02-10T07:00:00Z   \n",
       "9       athens-2004  2004-08-29T18:00:00Z  2004-08-13T06:00:00Z   \n",
       "\n",
       "        game_location         game_name game_season  game_year  \n",
       "0               China      Beijing 2022      Winter       2022  \n",
       "1               Japan        Tokyo 2020      Summer       2020  \n",
       "2   Republic of Korea  PyeongChang 2018      Winter       2018  \n",
       "3              Brazil          Rio 2016      Summer       2016  \n",
       "4  Russian Federation        Sochi 2014      Winter       2014  \n",
       "5       Great Britain       London 2012      Summer       2012  \n",
       "6              Canada    Vancouver 2010      Winter       2010  \n",
       "7               China      Beijing 2008      Summer       2008  \n",
       "8               Italy        Turin 2006      Winter       2006  \n",
       "9              Greece       Athens 2004      Summer       2004  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_host.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de ligne du dataframe: 53\n",
      "game_slug          0\n",
      "game_end_date      0\n",
      "game_start_date    0\n",
      "game_location      0\n",
      "game_name          0\n",
      "game_season        0\n",
      "game_year          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de ligne du dataframe:\", len(df_host))\n",
    "print(df_host.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_athletes.to_csv(\"Data/athletes.csv\",index=False)\n",
    "df_host.to_csv('Data/host.csv',index=False)\n",
    "df_medal.to_csv('Data/medal.csv',index=False)\n",
    "df_result.to_csv('Data/result.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement PYSPARK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/30 16:07:41 WARN Utils: Your hostname, MacBook-Air-de-DERDOUR.local resolves to a loopback address: 127.0.0.1; using 10.188.207.191 instead (on interface en0)\n",
      "24/05/30 16:07:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/30 16:07:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crer une session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hackathon\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum,countDistinct, when,count,collect_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_athletes = spark.read.csv(\"Data/athletes.csv\", header=True, inferSchema=True)\n",
    "data_host= spark.read.csv(\"Data/host.csv\", header=True, inferSchema=True)\n",
    "data_medal = spark.read.csv(\"Data/medal.csv\", header=True, inferSchema=True)\n",
    "data_result=spark.read.csv(\"Data/result.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Athletes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------------+------------------+------+--------+--------+------------+\n",
      "|         athlete_url|   athlete_full_name|games_participations|      first_game|athlete_year_birth|M_gold|M_silver|M_bronze|total_medals|\n",
      "+--------------------+--------------------+--------------------+----------------+------------------+------+--------+--------+------------+\n",
      "|https://olympics....|Cooper WOODS-TOPA...|                   1|    Beijing 2022|            2000.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      Felix ELOFSSON|                   2|PyeongChang 2018|            1995.0|     0|       0|       0|           0|\n",
      "|https://olympics....|       Dylan WALCZYK|                   1|    Beijing 2022|            1993.0|     0|       0|       0|           0|\n",
      "|https://olympics....|       Olli PENTTALA|                   1|    Beijing 2022|            1995.0|     0|       0|       0|           0|\n",
      "|https://olympics....|    Dmitriy REIKHERD|                   1|    Beijing 2022|            1989.0|     0|       0|       0|           0|\n",
      "|https://olympics....|         Matt GRAHAM|                   3|      Sochi 2014|            1994.0|     0|       1|       0|           1|\n",
      "|https://olympics....|     Ikuma HORISHIMA|                   2|PyeongChang 2018|            1997.0|     0|       0|       1|           1|\n",
      "|https://olympics....|         Daichi HARA|                   2|PyeongChang 2018|            1997.0|     0|       0|       1|           1|\n",
      "|https://olympics....|      Laurent DUMAIS|                   1|    Beijing 2022|            1996.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      James MATHESON|                   2|PyeongChang 2018|            1995.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      Pavel KOLMAKOV|                   3|      Sochi 2014|            1996.0|     0|       0|       0|           0|\n",
      "|https://olympics....|     Kosuke SUGIMOTO|                   1|    Beijing 2022|            1994.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      Brodie SUMMERS|                   3|      Sochi 2014|            1993.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      Severi VIERELA|                   1|    Beijing 2022|            2001.0|     0|       0|       0|           0|\n",
      "|https://olympics....|          Marco TADE|                   1|    Beijing 2022|            1995.0|     0|       0|       0|           0|\n",
      "|https://olympics....|     William FENELEY|                   1|    Beijing 2022|            1999.0|     0|       0|       0|           0|\n",
      "|https://olympics....|    Mikael KINGSBURY|                   3|      Sochi 2014|            1992.0|     1|       2|       0|           3|\n",
      "|https://olympics....|          So MATSUDA|                   1|    Beijing 2022|            1999.0|     0|       0|       0|           0|\n",
      "|https://olympics....|     Walter WALLBERG|                   2|PyeongChang 2018|            2000.0|     1|       0|       0|           1|\n",
      "|https://olympics....|      Bradley WILSON|                   3|      Sochi 2014|            1992.0|     0|       0|       0|           0|\n",
      "+--------------------+--------------------+--------------------+----------------+------------------+------+--------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_athletes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- athlete_url: string (nullable = true)\n",
      " |-- athlete_full_name: string (nullable = true)\n",
      " |-- games_participations: integer (nullable = true)\n",
      " |-- first_game: string (nullable = true)\n",
      " |-- athlete_year_birth: double (nullable = true)\n",
      " |-- M_gold: integer (nullable = true)\n",
      " |-- M_silver: integer (nullable = true)\n",
      " |-- M_bronze: integer (nullable = true)\n",
      " |-- total_medals: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_athletes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75904"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_athletes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_athletes=data_athletes.filter(\n",
    "   ~(data_athletes.athlete_full_name.isNull() & \n",
    "      data_athletes.games_participations.isNull() & \n",
    "      data_athletes.first_game.isNull() & \n",
    "      data_athletes.athlete_year_birth.isNull())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_athletes = data_athletes.dropna(subset=[\"first_game\"])\n",
    "data_athletes = data_athletes.dropna(subset=[\"athlete_year_birth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------------+------------------+------+--------+--------+------------+\n",
      "|         athlete_url|   athlete_full_name|games_participations|      first_game|athlete_year_birth|M_gold|M_silver|M_bronze|total_medals|\n",
      "+--------------------+--------------------+--------------------+----------------+------------------+------+--------+--------+------------+\n",
      "|https://olympics....|Cooper WOODS-TOPA...|                   1|    Beijing 2022|            2000.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      Felix ELOFSSON|                   2|PyeongChang 2018|            1995.0|     0|       0|       0|           0|\n",
      "|https://olympics....|       Dylan WALCZYK|                   1|    Beijing 2022|            1993.0|     0|       0|       0|           0|\n",
      "|https://olympics....|       Olli PENTTALA|                   1|    Beijing 2022|            1995.0|     0|       0|       0|           0|\n",
      "|https://olympics....|    Dmitriy REIKHERD|                   1|    Beijing 2022|            1989.0|     0|       0|       0|           0|\n",
      "|https://olympics....|         Matt GRAHAM|                   3|      Sochi 2014|            1994.0|     0|       1|       0|           1|\n",
      "|https://olympics....|     Ikuma HORISHIMA|                   2|PyeongChang 2018|            1997.0|     0|       0|       1|           1|\n",
      "|https://olympics....|         Daichi HARA|                   2|PyeongChang 2018|            1997.0|     0|       0|       1|           1|\n",
      "|https://olympics....|      Laurent DUMAIS|                   1|    Beijing 2022|            1996.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      James MATHESON|                   2|PyeongChang 2018|            1995.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      Pavel KOLMAKOV|                   3|      Sochi 2014|            1996.0|     0|       0|       0|           0|\n",
      "|https://olympics....|     Kosuke SUGIMOTO|                   1|    Beijing 2022|            1994.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      Brodie SUMMERS|                   3|      Sochi 2014|            1993.0|     0|       0|       0|           0|\n",
      "|https://olympics....|      Severi VIERELA|                   1|    Beijing 2022|            2001.0|     0|       0|       0|           0|\n",
      "|https://olympics....|          Marco TADE|                   1|    Beijing 2022|            1995.0|     0|       0|       0|           0|\n",
      "|https://olympics....|     William FENELEY|                   1|    Beijing 2022|            1999.0|     0|       0|       0|           0|\n",
      "|https://olympics....|    Mikael KINGSBURY|                   3|      Sochi 2014|            1992.0|     1|       2|       0|           3|\n",
      "|https://olympics....|          So MATSUDA|                   1|    Beijing 2022|            1999.0|     0|       0|       0|           0|\n",
      "|https://olympics....|     Walter WALLBERG|                   2|PyeongChang 2018|            2000.0|     1|       0|       0|           1|\n",
      "|https://olympics....|      Bradley WILSON|                   3|      Sochi 2014|            1992.0|     0|       0|       0|           0|\n",
      "+--------------------+--------------------+--------------------+----------------+------------------+------+--------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_athletes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+-----------------+----------+----------+\n",
      "|discipline_title|  event_title|   game_slug|participant_type|medal_type|rank_equal|rank_position|        country_name|country_code|country_3_letter_code|athlete_full_name|value_unit|value_type|\n",
      "+----------------+-------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+-----------------+----------+----------+\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      GOLD|     false|            1|               Italy|          IT|                  ITA|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|    SILVER|     false|            2|              Norway|          NO|                  NOR|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|    BRONZE|     false|            3|              Sweden|          SE|                  SWE|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            4|       Great Britain|          GB|                  GBR|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            5|              Canada|          CA|                  CAN|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            6|      Czech Republic|          CZ|                  CZE|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            7|         Switzerland|          CH|                  SUI|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            8|United States of ...|          US|                  USA|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            9|People's Republic...|          CN|                  CHN|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|           10|           Australia|          AU|                  AUS|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      GOLD|     false|            1|       Great Britain|          GB|                  GBR|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|    SILVER|     false|            2|               Japan|          JP|                  JPN|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|    BRONZE|     false|            3|              Sweden|          SE|                  SWE|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            4|         Switzerland|          CH|                  SUI|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            5|              Canada|          CA|                  CAN|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            6|United States of ...|          US|                  USA|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            7|People's Republic...|          CN|                  CHN|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            8|   Republic of Korea|          KR|                  KOR|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            9|             Denmark|          DK|                  DEN|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|           10|                 ROC|         ROC|                  ROC|             NULL|      NULL|      NULL|\n",
      "+----------------+-------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+-----------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- discipline_title: string (nullable = true)\n",
      " |-- event_title: string (nullable = true)\n",
      " |-- game_slug: string (nullable = true)\n",
      " |-- participant_type: string (nullable = true)\n",
      " |-- medal_type: string (nullable = true)\n",
      " |-- rank_equal: boolean (nullable = true)\n",
      " |-- rank_position: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country_3_letter_code: string (nullable = true)\n",
      " |-- athlete_full_name: string (nullable = true)\n",
      " |-- value_unit: string (nullable = true)\n",
      " |-- value_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+--------------------+----------+----------+\n",
      "|    discipline_title|         event_title|   game_slug|participant_type|medal_type|rank_equal|rank_position|        country_name|country_code|country_3_letter_code|   athlete_full_name|value_unit|value_type|\n",
      "+--------------------+--------------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+--------------------+----------+----------+\n",
      "|           Snowboard|Men's Snowboard S...|beijing-2022|         Athlete|      GOLD|     false|            1|              Canada|          CA|                  CAN|          Max PARROT|     70.11|    POINTS|\n",
      "|       Speed skating|       Women's 5000m|beijing-2022|         Athlete|    BRONZE|     false|            3|      Czech Republic|          CZ|                  CZE|   Martina SABLIKOVA|   6:50.09|      TIME|\n",
      "|            Biathlon|Women's 12.5km Ma...|beijing-2022|         Athlete|    BRONZE|     false|            3|              Norway|          NO|                  NOR|Marte Olsbu ROEIS...|   40:52.9|      TIME|\n",
      "|Cross Country Skiing|Men's 15km + 15km...|beijing-2022|         Athlete|      GOLD|     false|            1|                 ROC|         ROC|                  ROC| Alexander BOLSHUNOV| 1:16:09.8|      TIME|\n",
      "| Artistic Gymnastics|Women's Floor Exe...|  tokyo-2020|         Athlete|    SILVER|     false|            2|               Italy|          IT|                  ITA|     Vanessa FERRARI|    14.166|    POINTS|\n",
      "|       Weightlifting|        Men's +109kg|  tokyo-2020|         Athlete|    SILVER|     false|            2|Islamic Republic ...|          IR|                  IRI|         Ali DAVOUDI|       441|    WEIGHT|\n",
      "|           Athletics|Women's 400m Hurdles|  tokyo-2020|         Athlete|    BRONZE|     false|            3|         Netherlands|          NL|                  NED|           Femke BOL|     54043|      TIME|\n",
      "|           Athletics|      Men's Shot Put|  tokyo-2020|         Athlete|    SILVER|     false|            2|United States of ...|          US|                  USA|          Joe KOVACS|     20.93|  DISTANCE|\n",
      "|           Athletics| Men's Javelin Throw|  tokyo-2020|         Athlete|      GOLD|     false|            1|               India|          IN|                  IND|       Neeraj CHOPRA|     86.65|  DISTANCE|\n",
      "|            Biathlon|Women's 15km Indi...|beijing-2022|         Athlete|    SILVER|     false|            2|              France|          FR|                  FRA|     Anais CHEVALIER|   44:22.1|      TIME|\n",
      "|       Alpine Skiing|  Men's Giant Slalom|beijing-2022|         Athlete|    BRONZE|     false|            3|              France|          FR|                  FRA|      Mathieu FAIVRE|   2:10.69|      TIME|\n",
      "|      Sport Climbing|      Men's Combined|  tokyo-2020|         Athlete|    SILVER|     false|            2|United States of ...|          US|                  USA|   Nathaniel COLEMAN|        30|    POINTS|\n",
      "|           Athletics|   Women's Long Jump|  tokyo-2020|         Athlete|      GOLD|     false|            1|             Germany|          DE|                  GER|     Malaika MIHAMBO|      6.98|  DISTANCE|\n",
      "|            Swimming|Men's 100m Backst...|  tokyo-2020|         Athlete|      GOLD|     false|            1|                 ROC|         ROC|                  ROC|        Evgeny RYLOV|     53022|      TIME|\n",
      "|           Snowboard|Women's Snowboard...|beijing-2022|         Athlete|      GOLD|     false|            1|United States of ...|          US|                  USA|           Chloe KIM|     87.75|    POINTS|\n",
      "|Cross Country Skiing|Women's 10km Classic|beijing-2022|         Athlete|    BRONZE|     false|            3|             Finland|          FI|                  FIN|   Krista PARMAKOSKI|   28:37.8|      TIME|\n",
      "|           Snowboard|Men's Snowboard B...|beijing-2022|         Athlete|    SILVER|     false|            2|              Norway|          NO|                  NOR|       Mons ROISLAND|    146.50|    POINTS|\n",
      "|Cross Country Skiing|Men's 15km + 15km...|beijing-2022|         Athlete|    SILVER|     false|            2|                 ROC|         ROC|                  ROC|       Denis SPITSOV| 1:17:20.8|      TIME|\n",
      "| Artistic Gymnastics|         Men's Rings|  tokyo-2020|         Athlete|      GOLD|     false|            1|People's Republic...|          CN|                  CHN|            Yang LIU|    15.300|    POINTS|\n",
      "|           Athletics|        Women's 200m|  tokyo-2020|         Athlete|      GOLD|     false|            1|             Jamaica|          JM|                  JAM|     Elaine THOMPSON|     22086|      TIME|\n",
      "+--------------------+--------------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_result.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "162804"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|    discipline_title|count|\n",
      "+--------------------+-----+\n",
      "|              Tennis| 2297|\n",
      "|              Boxing| 6816|\n",
      "|          Ice Hockey|  349|\n",
      "|   Marathon Swimming|  202|\n",
      "|                Golf|  385|\n",
      "|              Rowing| 2812|\n",
      "|                Judo| 3803|\n",
      "|   Baseball/Softball|   12|\n",
      "|            Softball|   32|\n",
      "|             Sailing| 3886|\n",
      "|            Swimming|14704|\n",
      "|         Cycling BMX|  108|\n",
      "|Cycling BMX Frees...|   18|\n",
      "|       Alpine Skiing|10185|\n",
      "|          Basketball|  408|\n",
      "|            Handball|  276|\n",
      "| Rhythmic Gymnastics|   18|\n",
      "|            Biathlon| 5057|\n",
      "|              Karate|   81|\n",
      "|           Triathlon|  652|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_result.groupBy(\"discipline_title\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|participant_type| count|\n",
      "+----------------+------+\n",
      "|         Athlete|141646|\n",
      "|        GameTeam| 21158|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_result.groupBy(\"participant_type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|medal_type| count|\n",
      "+----------+------+\n",
      "|      NULL|142598|\n",
      "|    SILVER|  6568|\n",
      "|      GOLD|  6609|\n",
      "|    BRONZE|  7029|\n",
      "+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_result.groupBy(\"medal_type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|participant_type| count|\n",
      "+----------------+------+\n",
      "|         Athlete|141646|\n",
      "|        GameTeam| 21158|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_result.groupBy(\"participant_type\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|          game_slug|count|\n",
      "+-------------------+-----+\n",
      "|         sochi-2014| 3666|\n",
      "|       beijing-2022| 3784|\n",
      "|        london-2012| 7531|\n",
      "|     vancouver-2010| 3322|\n",
      "|       beijing-2008| 7360|\n",
      "|         tokyo-2020| 6863|\n",
      "|           rio-2016| 7672|\n",
      "|   pyeongchang-2018| 3707|\n",
      "|        nagano-1998| 2659|\n",
      "|        athens-2004| 6979|\n",
      "|salt-lake-city-2002| 3008|\n",
      "|         turin-2006| 3256|\n",
      "|       atlanta-1996| 7117|\n",
      "|   albertville-1992| 2783|\n",
      "|     barcelona-1992| 6878|\n",
      "|   lillehammer-1994| 2451|\n",
      "|        sydney-2000| 7091|\n",
      "|      sarajevo-1984| 1664|\n",
      "|   mexico-city-1968| 3569|\n",
      "|      montreal-1976| 3670|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_result.groupBy(\"game_slug\").count().show()\n",
    "data_result.groupBy(\"game_slug\").count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         event_title|count|\n",
      "+--------------------+-----+\n",
      "|Men's Snowboard S...|   30|\n",
      "|     Women's Monobob|   20|\n",
      "|Men's Light Heavy...|   22|\n",
      "|    110m hurdles men|  313|\n",
      "|sabre individual men|  583|\n",
      "|          Keirin men|   88|\n",
      "|   4x7.5km relay men|   19|\n",
      "|K2 1000m kayak do...|  169|\n",
      "|60 66kg halflight...|  129|\n",
      "|Beijing 2008 Taek...|   16|\n",
      "|     Women's Madison|   15|\n",
      "|          Men's 96kg|   13|\n",
      "|       Dressage Team|   15|\n",
      "|Women's 4 x 100m ...|    8|\n",
      "|Ladies 3000m R...|    8|\n",
      "|Ladies Alpine ...|   32|\n",
      "|Men's Parallel Gi...|   32|\n",
      "|        Women's 200m|    8|\n",
      "|  10m platform women|  416|\n",
      "|100m backstroke w...|  489|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_result.groupBy(\"event_title\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|rank_equal| count|\n",
      "+----------+------+\n",
      "|      NULL|130278|\n",
      "|      true| 23613|\n",
      "|     false|  8913|\n",
      "+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_result.groupBy(\"rank_equal\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>distinct_code_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country_name, distinct_code_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_result_grouped = data_result.groupBy('country_name').agg(countDistinct('country_3_letter_code').alias('distinct_code_count'))\n",
    "\n",
    "# Filter countries with more than one distinct code\n",
    "data_result_filtered = data_result_grouped.filter(col('distinct_code_count') > 1)\n",
    "\n",
    "# Convert the result back to Pandas DataFrame for display\n",
    "data_result_filtered_pandas = data_result_filtered.toPandas()\n",
    "\n",
    "\n",
    "\n",
    "# Show the filtered dataframe\n",
    "data_result_filtered_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_3_letter_code</th>\n",
       "      <th>DistinctCountryCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IVB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIV</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISV</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SWZ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MKD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_3_letter_code  DistinctCountryCount\n",
       "0                   IVB                     2\n",
       "1                   CIV                     2\n",
       "2                   ISV                     2\n",
       "3                   SWZ                     2\n",
       "4                   MKD                     2"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by country_3_letter_code and count distinct country_name\n",
    "data_result_grouped = data_result.groupBy('country_3_letter_code').agg(countDistinct('country_name').alias('DistinctCountryCount'))\n",
    "\n",
    "# Filter codes with more than one distinct country\n",
    "data_result_filtered = data_result_grouped.filter(data_result_grouped['DistinctCountryCount'] > 1)\n",
    "data_result_filtered_pandas = data_result_filtered.toPandas()\n",
    "data_result_filtered_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US Virgin Islands</td>\n",
       "      <td>ISV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swaziland</td>\n",
       "      <td>SWZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cte d'Ivoire</td>\n",
       "      <td>CIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virgin Islands, British</td>\n",
       "      <td>IVB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Former Yugoslav Republic of Macedonia</td>\n",
       "      <td>MKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>British Virgin Islands</td>\n",
       "      <td>IVB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eswatini</td>\n",
       "      <td>SWZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>MKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Virgin Islands, US</td>\n",
       "      <td>ISV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>CIV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                country_name country_3_letter_code\n",
       "0                          US Virgin Islands                   ISV\n",
       "1                                  Swaziland                   SWZ\n",
       "2                             Cte d'Ivoire                   CIV\n",
       "3                    Virgin Islands, British                   IVB\n",
       "4  The Former Yugoslav Republic of Macedonia                   MKD\n",
       "5                     British Virgin Islands                   IVB\n",
       "6                                   Eswatini                   SWZ\n",
       "7                            North Macedonia                   MKD\n",
       "8                         Virgin Islands, US                   ISV\n",
       "9                                Ivory Coast                   CIV"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by country_3_letter_code and count distinct country_name\n",
    "data_result_grouped = data_result.groupBy('country_3_letter_code').agg(countDistinct('country_name').alias('DistinctCountryCount'))\n",
    "\n",
    "# Filter codes with more than one distinct country\n",
    "data_result_filtered = data_result_grouped.filter(data_result_grouped['DistinctCountryCount'] > 1)\n",
    "\n",
    "# Collect the list of codes with more than one country\n",
    "codes_with_multiple_countries = [row['country_3_letter_code'] for row in data_result_filtered.collect()]\n",
    "\n",
    "# Filter the original DataFrame to show rows with the specified codes\n",
    "df_filtered_rows = data_result.filter(col('country_3_letter_code').isin(codes_with_multiple_countries))\n",
    "\n",
    "# Select distinct pairs of country_name and country_3_letter_code\n",
    "df_distinct_pairs = df_filtered_rows.select('country_name', 'country_3_letter_code').distinct()\n",
    "data_result_filtered_pandas = df_distinct_pairs.toPandas()\n",
    "\n",
    "# Show the filtered dataframe\n",
    "data_result_filtered_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>event_title</th>\n",
       "      <th>game_slug</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>rank_equal</th>\n",
       "      <th>rank_position</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>value_unit</th>\n",
       "      <th>value_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Italy</td>\n",
       "      <td>IT</td>\n",
       "      <td>ITA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Norway</td>\n",
       "      <td>NO</td>\n",
       "      <td>NOR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>BRONZE</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SE</td>\n",
       "      <td>SWE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>GB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Curling</td>\n",
       "      <td>Mixed Doubles</td>\n",
       "      <td>beijing-2022</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CA</td>\n",
       "      <td>CAN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162799</th>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Normal Hill Individual men</td>\n",
       "      <td>chamonix-1924</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DNS</td>\n",
       "      <td>Poland</td>\n",
       "      <td>PL</td>\n",
       "      <td>POL</td>\n",
       "      <td>Franciszek BUJAK</td>\n",
       "      <td>None</td>\n",
       "      <td>IRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162800</th>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Normal Hill Individual men</td>\n",
       "      <td>chamonix-1924</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DNS</td>\n",
       "      <td>Poland</td>\n",
       "      <td>PL</td>\n",
       "      <td>POL</td>\n",
       "      <td>Henryk Mckenbrunn</td>\n",
       "      <td>None</td>\n",
       "      <td>IRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162801</th>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Normal Hill Individual men</td>\n",
       "      <td>chamonix-1924</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DNS</td>\n",
       "      <td>Czechoslovakia</td>\n",
       "      <td>CSHH</td>\n",
       "      <td>TCH</td>\n",
       "      <td>Milda Prokopec</td>\n",
       "      <td>None</td>\n",
       "      <td>IRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162802</th>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Normal Hill Individual men</td>\n",
       "      <td>chamonix-1924</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DNS</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>Sigurd Overby</td>\n",
       "      <td>None</td>\n",
       "      <td>IRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162803</th>\n",
       "      <td>Gymnastics Artistic</td>\n",
       "      <td>26th Federal Festival, Society and Association...</td>\n",
       "      <td>paris-1900</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>France</td>\n",
       "      <td>FR</td>\n",
       "      <td>FRA</td>\n",
       "      <td>None</td>\n",
       "      <td>142 pts</td>\n",
       "      <td>POINTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162804 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           discipline_title  \\\n",
       "0                   Curling   \n",
       "1                   Curling   \n",
       "2                   Curling   \n",
       "3                   Curling   \n",
       "4                   Curling   \n",
       "...                     ...   \n",
       "162799          Ski Jumping   \n",
       "162800          Ski Jumping   \n",
       "162801          Ski Jumping   \n",
       "162802          Ski Jumping   \n",
       "162803  Gymnastics Artistic   \n",
       "\n",
       "                                              event_title      game_slug  \\\n",
       "0                                           Mixed Doubles   beijing-2022   \n",
       "1                                           Mixed Doubles   beijing-2022   \n",
       "2                                           Mixed Doubles   beijing-2022   \n",
       "3                                           Mixed Doubles   beijing-2022   \n",
       "4                                           Mixed Doubles   beijing-2022   \n",
       "...                                                   ...            ...   \n",
       "162799                         Normal Hill Individual men  chamonix-1924   \n",
       "162800                         Normal Hill Individual men  chamonix-1924   \n",
       "162801                         Normal Hill Individual men  chamonix-1924   \n",
       "162802                         Normal Hill Individual men  chamonix-1924   \n",
       "162803  26th Federal Festival, Society and Association...     paris-1900   \n",
       "\n",
       "       participant_type medal_type rank_equal rank_position  \\\n",
       "0              GameTeam       GOLD      False             1   \n",
       "1              GameTeam     SILVER      False             2   \n",
       "2              GameTeam     BRONZE      False             3   \n",
       "3              GameTeam       None      False             4   \n",
       "4              GameTeam       None      False             5   \n",
       "...                 ...        ...        ...           ...   \n",
       "162799          Athlete       None       None           DNS   \n",
       "162800          Athlete       None       None           DNS   \n",
       "162801          Athlete       None       None           DNS   \n",
       "162802          Athlete       None       None           DNS   \n",
       "162803         GameTeam       None       None             1   \n",
       "\n",
       "                    country_name country_code country_3_letter_code  \\\n",
       "0                          Italy           IT                   ITA   \n",
       "1                         Norway           NO                   NOR   \n",
       "2                         Sweden           SE                   SWE   \n",
       "3                  Great Britain           GB                   GBR   \n",
       "4                         Canada           CA                   CAN   \n",
       "...                          ...          ...                   ...   \n",
       "162799                    Poland           PL                   POL   \n",
       "162800                    Poland           PL                   POL   \n",
       "162801            Czechoslovakia         CSHH                   TCH   \n",
       "162802  United States of America           US                   USA   \n",
       "162803                    France           FR                   FRA   \n",
       "\n",
       "          athlete_full_name value_unit value_type  \n",
       "0                      None       None       None  \n",
       "1                      None       None       None  \n",
       "2                      None       None       None  \n",
       "3                      None       None       None  \n",
       "4                      None       None       None  \n",
       "...                     ...        ...        ...  \n",
       "162799     Franciszek BUJAK       None        IRM  \n",
       "162800  Henryk Mckenbrunn       None        IRM  \n",
       "162801       Milda Prokopec       None        IRM  \n",
       "162802        Sigurd Overby       None        IRM  \n",
       "162803                 None    142 pts     POINTS  \n",
       "\n",
       "[162804 rows x 13 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "data_result_updated = data_result.withColumn(\n",
    "    'country_name',\n",
    "     when(col('country_3_letter_code') == 'MKD', 'Republic of North Macedonia')\n",
    "    .when(col('country_3_letter_code') == 'ISV', 'Virgin Islands, US')\n",
    "    .when(col('country_3_letter_code') == 'IVB', 'Virgin Islands, British')\n",
    "    .when(col('country_3_letter_code') == 'CIV', 'Ivory Coast')\n",
    "    .when(col('country_3_letter_code') == 'SWZ', 'Eswatini')\n",
    "    .otherwise(col('country_name'))\n",
    ")\n",
    "data_result_filtered_pandas = data_result_updated.toPandas()\n",
    "data_result_filtered_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country_name, country_3_letter_code]\n",
       "Index: []"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by country_3_letter_code and count distinct country_name\n",
    "data_result_grouped = data_result_updated.groupBy('country_3_letter_code').agg(countDistinct('country_name').alias('DistinctCountryCount'))\n",
    "\n",
    "# Filter codes with more than one distinct country\n",
    "data_result_filtered = data_result_grouped.filter(data_result_grouped['DistinctCountryCount'] > 1)\n",
    "\n",
    "# Collect the list of codes with more than one country\n",
    "codes_with_multiple_countries = [row['country_3_letter_code'] for row in data_result_filtered.collect()]\n",
    "\n",
    "# Filter the original DataFrame to show rows with the specified codes\n",
    "df_filtered_rows = data_result.filter(col('country_3_letter_code').isin(codes_with_multiple_countries))\n",
    "\n",
    "# Select distinct pairs of country_name and country_3_letter_code\n",
    "df_distinct_pairs = df_filtered_rows.select('country_name', 'country_3_letter_code').distinct()\n",
    "data_result_filtered_pandas = df_distinct_pairs.toPandas()\n",
    "\n",
    "# Show the filtered dataframe\n",
    "data_result_filtered_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result = data_result_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australasia</td>\n",
       "      <td>None</td>\n",
       "      <td>ANZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bohemia</td>\n",
       "      <td>None</td>\n",
       "      <td>BOH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Korea Team</td>\n",
       "      <td>None</td>\n",
       "      <td>COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lebanon</td>\n",
       "      <td>None</td>\n",
       "      <td>LBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MIX</td>\n",
       "      <td>None</td>\n",
       "      <td>MIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Malaya</td>\n",
       "      <td>None</td>\n",
       "      <td>MAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Namibia</td>\n",
       "      <td>None</td>\n",
       "      <td>NAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Newfoundland</td>\n",
       "      <td>None</td>\n",
       "      <td>NFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>None</td>\n",
       "      <td>NGR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>North Borneo</td>\n",
       "      <td>None</td>\n",
       "      <td>NBO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Norway</td>\n",
       "      <td>None</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Olympic Athletes from Russia</td>\n",
       "      <td>None</td>\n",
       "      <td>OAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Refugee Olympic Athletes</td>\n",
       "      <td>None</td>\n",
       "      <td>XXB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Refugee Olympic Team</td>\n",
       "      <td>None</td>\n",
       "      <td>EOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Saar</td>\n",
       "      <td>None</td>\n",
       "      <td>SAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>SGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>South Vietnam</td>\n",
       "      <td>None</td>\n",
       "      <td>VNM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>None</td>\n",
       "      <td>URS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Unified Team</td>\n",
       "      <td>None</td>\n",
       "      <td>EUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>United Arab Republic</td>\n",
       "      <td>None</td>\n",
       "      <td>UAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>West Indies Federation</td>\n",
       "      <td>None</td>\n",
       "      <td>WIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>None</td>\n",
       "      <td>ZAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    country_name country_code country_3_letter_code\n",
       "0                    Australasia         None                   ANZ\n",
       "1                        Bohemia         None                   BOH\n",
       "2                     Korea Team         None                   COR\n",
       "3                        Lebanon         None                   LBN\n",
       "4                            MIX         None                   MIX\n",
       "5                         Malaya         None                   MAL\n",
       "6                        Namibia         None                   NAM\n",
       "7                   Newfoundland         None                   NFL\n",
       "8                        Nigeria         None                   NGR\n",
       "9                   North Borneo         None                   NBO\n",
       "10                        Norway         None                   NOR\n",
       "11  Olympic Athletes from Russia         None                   OAR\n",
       "12      Refugee Olympic Athletes         None                   XXB\n",
       "13          Refugee Olympic Team         None                   EOR\n",
       "14                          Saar         None                   SAA\n",
       "15                     Singapore         None                   SGP\n",
       "16                 South Vietnam         None                   VNM\n",
       "17                  Soviet Union         None                   URS\n",
       "18                  Unified Team         None                   EUN\n",
       "19          United Arab Republic         None                   UAR\n",
       "20        West Indies Federation         None                   WIF\n",
       "21                        Zambia         None                   ZAM"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter countries without a country code\n",
    "countries_without_code = data_result.filter((col(\"country_code\").isNull()) | (col(\"country_code\") == \"\") |\n",
    "                                   (col(\"country_3_letter_code\").isNull()) | (col(\"country_3_letter_code\") == \"\"))\n",
    "\n",
    "# Select relevant columns to display\n",
    "countries_without_code_show = countries_without_code.select(\"country_name\", \"country_code\", \"country_3_letter_code\").dropDuplicates([\"country_name\"])\n",
    "countries_show = countries_without_code_show.toPandas()\n",
    "countries_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without a country code: 5036\n"
     ]
    }
   ],
   "source": [
    "countries_without_code_number=countries_without_code.count()\n",
    "print(f\"Number of rows without a country code: {countries_without_code_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>event_title</th>\n",
       "      <th>game_slug</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>rank_equal</th>\n",
       "      <th>rank_position</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "      <th>athlete_full_name</th>\n",
       "      <th>value_unit</th>\n",
       "      <th>value_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skeleton</td>\n",
       "      <td>Men</td>\n",
       "      <td>pyeongchang-2018</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>Olympic Athletes from Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Nikita TREGUBOV</td>\n",
       "      <td>202180</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skeleton</td>\n",
       "      <td>Men</td>\n",
       "      <td>pyeongchang-2018</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>Olympic Athletes from Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Vladislav MARCHENKOV</td>\n",
       "      <td>205180</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speed skating</td>\n",
       "      <td>Ladies 500m</td>\n",
       "      <td>pyeongchang-2018</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>Olympic Athletes from Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Angelina GOLIKOVA</td>\n",
       "      <td>37620</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Speed skating</td>\n",
       "      <td>Mens 1500m</td>\n",
       "      <td>pyeongchang-2018</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>Olympic Athletes from Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Sergey TROFIMOV</td>\n",
       "      <td>106690</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speed skating</td>\n",
       "      <td>Ladies 3000m</td>\n",
       "      <td>pyeongchang-2018</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>Olympic Athletes from Russia</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Natalia VORONINA</td>\n",
       "      <td>245850</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>Alpine Skiing</td>\n",
       "      <td>slalom men</td>\n",
       "      <td>lake-placid-1980</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DNF</td>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Aleksandr ZHIROV</td>\n",
       "      <td>None</td>\n",
       "      <td>IRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>Alpine Skiing</td>\n",
       "      <td>slalom men</td>\n",
       "      <td>lake-placid-1980</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DNS</td>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>Valery Tsyganov</td>\n",
       "      <td>None</td>\n",
       "      <td>IRM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>Figure skating</td>\n",
       "      <td>Ice dancing mixed</td>\n",
       "      <td>innsbruck-1976</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>None</td>\n",
       "      <td>91+</td>\n",
       "      <td>RANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>Figure skating</td>\n",
       "      <td>Ice dancing mixed</td>\n",
       "      <td>innsbruck-1976</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>None</td>\n",
       "      <td>72+</td>\n",
       "      <td>RANK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>Figure skating</td>\n",
       "      <td>Ice dancing mixed</td>\n",
       "      <td>innsbruck-1976</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>RU</td>\n",
       "      <td>RUS</td>\n",
       "      <td>None</td>\n",
       "      <td>84+</td>\n",
       "      <td>RANK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3270 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     discipline_title        event_title         game_slug participant_type  \\\n",
       "0            Skeleton                Men  pyeongchang-2018          Athlete   \n",
       "1            Skeleton                Men  pyeongchang-2018          Athlete   \n",
       "2       Speed skating     Ladies 500m  pyeongchang-2018          Athlete   \n",
       "3       Speed skating      Mens 1500m  pyeongchang-2018          Athlete   \n",
       "4       Speed skating    Ladies 3000m  pyeongchang-2018          Athlete   \n",
       "...               ...                ...               ...              ...   \n",
       "3265    Alpine Skiing         slalom men  lake-placid-1980          Athlete   \n",
       "3266    Alpine Skiing         slalom men  lake-placid-1980          Athlete   \n",
       "3267   Figure skating  Ice dancing mixed    innsbruck-1976         GameTeam   \n",
       "3268   Figure skating  Ice dancing mixed    innsbruck-1976         GameTeam   \n",
       "3269   Figure skating  Ice dancing mixed    innsbruck-1976         GameTeam   \n",
       "\n",
       "     medal_type rank_equal rank_position                  country_name  \\\n",
       "0        SILVER       None             2  Olympic Athletes from Russia   \n",
       "1          None       None            15  Olympic Athletes from Russia   \n",
       "2          None       None             7  Olympic Athletes from Russia   \n",
       "3          None       None            18  Olympic Athletes from Russia   \n",
       "4          None       None            10  Olympic Athletes from Russia   \n",
       "...         ...        ...           ...                           ...   \n",
       "3265       None       None           DNF                  Soviet Union   \n",
       "3266       None       None           DNS                  Soviet Union   \n",
       "3267       GOLD       None             1                  Soviet Union   \n",
       "3268     SILVER       None             2                  Soviet Union   \n",
       "3269       None       None             4                  Soviet Union   \n",
       "\n",
       "     country_code country_3_letter_code     athlete_full_name value_unit  \\\n",
       "0              RU                   RUS       Nikita TREGUBOV     202180   \n",
       "1              RU                   RUS  Vladislav MARCHENKOV     205180   \n",
       "2              RU                   RUS     Angelina GOLIKOVA      37620   \n",
       "3              RU                   RUS       Sergey TROFIMOV     106690   \n",
       "4              RU                   RUS      Natalia VORONINA     245850   \n",
       "...           ...                   ...                   ...        ...   \n",
       "3265           RU                   RUS      Aleksandr ZHIROV       None   \n",
       "3266           RU                   RUS       Valery Tsyganov       None   \n",
       "3267           RU                   RUS                  None      91+   \n",
       "3268           RU                   RUS                  None      72+   \n",
       "3269           RU                   RUS                  None      84+   \n",
       "\n",
       "     value_type  \n",
       "0          TIME  \n",
       "1          TIME  \n",
       "2          TIME  \n",
       "3          TIME  \n",
       "4          TIME  \n",
       "...         ...  \n",
       "3265        IRM  \n",
       "3266        IRM  \n",
       "3267       RANK  \n",
       "3268       RANK  \n",
       "3269       RANK  \n",
       "\n",
       "[3270 rows x 13 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_result_last = data_result.withColumn(\n",
    "    \"country_3_letter_code\",\n",
    "    when(\n",
    "        col(\"country_name\").contains(\"Olympic Athletes from Russia\"), \"RUS\"\n",
    "    ).when(\n",
    "        col(\"country_name\").contains(\"Soviet Union\"), \"RUS\"\n",
    "    ).otherwise(col(\"country_3_letter_code\"))\n",
    ").withColumn(\n",
    "    \"country_code\",\n",
    "    when(\n",
    "        col(\"country_name\").contains(\"Olympic Athletes from Russia\"), \"RU\"\n",
    "    ).when(\n",
    "        col(\"country_name\").contains(\"Soviet Union\"), \"RU\"\n",
    "    ).otherwise(col(\"country_code\"))\n",
    ")\n",
    "\n",
    "# Display the updated rows for verification\n",
    "data_result_last_show = data_result_last.filter(\n",
    "    (col(\"country_name\").contains(\"Olympic Athletes from Russia\")) |\n",
    "    (col(\"country_name\").contains(\"Soviet Union\"))\n",
    ")\n",
    "data_result_last_show = data_result_last_show.toPandas()\n",
    "data_result_last_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discipline_title         3270\n",
       "event_title              3270\n",
       "game_slug                3270\n",
       "participant_type         3270\n",
       "medal_type               1221\n",
       "rank_equal                300\n",
       "rank_position            3248\n",
       "country_name             3270\n",
       "country_code             3270\n",
       "country_3_letter_code    3270\n",
       "athlete_full_name        2808\n",
       "value_unit               2275\n",
       "value_type               2391\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_result_last_show.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows without a country code: 1766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Filter countries without a country code\n",
    "countries_without_code = data_result_last.filter((col(\"country_code\").isNull()) | (col(\"country_code\") == \"\") |\n",
    "                                   (col(\"country_3_letter_code\").isNull()) | (col(\"country_3_letter_code\") == \"\"))\n",
    "\n",
    "# Select relevant columns to display\n",
    "countries_without_code_show = countries_without_code.select(\"country_name\", \"country_code\", \"country_3_letter_code\").dropDuplicates([\"country_name\"])\n",
    "countries_without_code_number=countries_without_code.count()\n",
    "print(f\"Number of rows without a country code: {countries_without_code_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with an empty country_code\n",
    "data_result = data_result_last.filter((col(\"country_code\").isNotNull()) & (col(\"country_code\") != \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+-----------------+----------+----------+\n",
      "|discipline_title|  event_title|   game_slug|participant_type|medal_type|rank_equal|rank_position|        country_name|country_code|country_3_letter_code|athlete_full_name|value_unit|value_type|\n",
      "+----------------+-------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+-----------------+----------+----------+\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      GOLD|     false|            1|               Italy|          IT|                  ITA|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|    SILVER|     false|            2|              Norway|          NO|                  NOR|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|    BRONZE|     false|            3|              Sweden|          SE|                  SWE|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            4|       Great Britain|          GB|                  GBR|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            5|              Canada|          CA|                  CAN|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            6|      Czech Republic|          CZ|                  CZE|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            7|         Switzerland|          CH|                  SUI|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            8|United States of ...|          US|                  USA|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|            9|People's Republic...|          CN|                  CHN|             NULL|      NULL|      NULL|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|     false|           10|           Australia|          AU|                  AUS|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      GOLD|     false|            1|       Great Britain|          GB|                  GBR|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|    SILVER|     false|            2|               Japan|          JP|                  JPN|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|    BRONZE|     false|            3|              Sweden|          SE|                  SWE|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            4|         Switzerland|          CH|                  SUI|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            5|              Canada|          CA|                  CAN|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            6|United States of ...|          US|                  USA|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            7|People's Republic...|          CN|                  CHN|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            8|   Republic of Korea|          KR|                  KOR|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|            9|             Denmark|          DK|                  DEN|             NULL|      NULL|      NULL|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|     false|           10|                 ROC|         ROC|                  ROC|             NULL|      NULL|      NULL|\n",
      "+----------------+-------------+------------+----------------+----------+----------+-------------+--------------------+------------+---------------------+-----------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result=data_result.drop(\"athlete_full_name\")\n",
    "data_result=data_result.drop(\"value_unit\")\n",
    "data_result=data_result.drop(\"value_type\")\n",
    "data_result=data_result.drop(\"country_code\")\n",
    "data_result=data_result.drop(\"rank_equal\")\n",
    "data_result=data_result.drop(\"rank_equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------------+----------------+----------+-------------+--------------------+---------------------+\n",
      "|discipline_title|  event_title|   game_slug|participant_type|medal_type|rank_position|        country_name|country_3_letter_code|\n",
      "+----------------+-------------+------------+----------------+----------+-------------+--------------------+---------------------+\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      GOLD|            1|               Italy|                  ITA|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|    SILVER|            2|              Norway|                  NOR|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|    BRONZE|            3|              Sweden|                  SWE|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|            4|       Great Britain|                  GBR|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|            5|              Canada|                  CAN|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|            6|      Czech Republic|                  CZE|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|            7|         Switzerland|                  SUI|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|            8|United States of ...|                  USA|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|            9|People's Republic...|                  CHN|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      NULL|           10|           Australia|                  AUS|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      GOLD|            1|       Great Britain|                  GBR|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|    SILVER|            2|               Japan|                  JPN|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|    BRONZE|            3|              Sweden|                  SWE|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|            4|         Switzerland|                  SUI|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|            5|              Canada|                  CAN|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|            6|United States of ...|                  USA|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|            7|People's Republic...|                  CHN|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|            8|   Republic of Korea|                  KOR|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|            9|             Denmark|                  DEN|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      NULL|           10|                 ROC|                  ROC|\n",
      "+----------------+-------------+------------+----------------+----------+-------------+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result = data_result.fillna('0', subset=[\"medal_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+------------+----------------+----------+-------------+--------------------+---------------------+\n",
      "|discipline_title|  event_title|   game_slug|participant_type|medal_type|rank_position|        country_name|country_3_letter_code|\n",
      "+----------------+-------------+------------+----------------+----------+-------------+--------------------+---------------------+\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|      GOLD|            1|               Italy|                  ITA|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|    SILVER|            2|              Norway|                  NOR|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|    BRONZE|            3|              Sweden|                  SWE|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|         0|            4|       Great Britain|                  GBR|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|         0|            5|              Canada|                  CAN|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|         0|            6|      Czech Republic|                  CZE|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|         0|            7|         Switzerland|                  SUI|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|         0|            8|United States of ...|                  USA|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|         0|            9|People's Republic...|                  CHN|\n",
      "|         Curling|Mixed Doubles|beijing-2022|        GameTeam|         0|           10|           Australia|                  AUS|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|      GOLD|            1|       Great Britain|                  GBR|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|    SILVER|            2|               Japan|                  JPN|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|    BRONZE|            3|              Sweden|                  SWE|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|         0|            4|         Switzerland|                  SUI|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|         0|            5|              Canada|                  CAN|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|         0|            6|United States of ...|                  USA|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|         0|            7|People's Republic...|                  CHN|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|         0|            8|   Republic of Korea|                  KOR|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|         0|            9|             Denmark|                  DEN|\n",
      "|         Curling|        Women|beijing-2022|        GameTeam|         0|           10|                 ROC|                  ROC|\n",
      "+----------------+-------------+------------+----------------+----------+-------------+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEDAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------------+------------+----------+----------------+-----------------+--------------------+--------------------+--------------------+------------+---------------------+\n",
      "|discipline_title|   game_slug|         event_title|event_gender|medal_type|participant_type|participant_title|         athlete_url|   athlete_full_name|        country_name|country_code|country_3_letter_code|\n",
      "+----------------+------------+--------------------+------------+----------+----------------+-----------------+--------------------+--------------------+--------------------+------------+---------------------+\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|      GOLD|        GameTeam|            Italy|https://olympics....|Stefania CONSTANTINI|               Italy|          IT|                  ITA|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|      GOLD|        GameTeam|            Italy|https://olympics....|        Amos MOSANER|               Italy|          IT|                  ITA|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|    SILVER|        GameTeam|           Norway|https://olympics....|    Kristin SKASLIEN|              Norway|          NO|                  NOR|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|    SILVER|        GameTeam|           Norway|https://olympics....|  Magnus NEDREGOTTEN|              Norway|          NO|                  NOR|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|    BRONZE|        GameTeam|           Sweden|https://olympics....|       Almida DE VAL|              Sweden|          SE|                  SWE|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|    BRONZE|        GameTeam|           Sweden|https://olympics....|      Oskar ERIKSSON|              Sweden|          SE|                  SWE|\n",
      "|         Curling|beijing-2022|               Women|       Women|      GOLD|        GameTeam|    Great Britain|                NULL|                NULL|       Great Britain|          GB|                  GBR|\n",
      "|         Curling|beijing-2022|               Women|       Women|    SILVER|        GameTeam|            Japan|                NULL|                NULL|               Japan|          JP|                  JPN|\n",
      "|         Curling|beijing-2022|               Women|       Women|    BRONZE|        GameTeam|           Sweden|                NULL|                NULL|              Sweden|          SE|                  SWE|\n",
      "|         Curling|beijing-2022|                 Men|         Men|      GOLD|        GameTeam|           Sweden|                NULL|                NULL|              Sweden|          SE|                  SWE|\n",
      "|         Curling|beijing-2022|                 Men|         Men|    SILVER|        GameTeam|    Great Britain|                NULL|                NULL|       Great Britain|          GB|                  GBR|\n",
      "|         Curling|beijing-2022|                 Men|         Men|    BRONZE|        GameTeam|           Canada|                NULL|                NULL|              Canada|          CA|                  CAN|\n",
      "|Freestyle Skiing|beijing-2022|        Men's Moguls|         Men|    SILVER|         Athlete|             NULL|https://olympics....|    Mikael KINGSBURY|              Canada|          CA|                  CAN|\n",
      "|Freestyle Skiing|beijing-2022|        Men's Moguls|         Men|      GOLD|         Athlete|             NULL|https://olympics....|     Walter WALLBERG|              Sweden|          SE|                  SWE|\n",
      "|Freestyle Skiing|beijing-2022|        Men's Moguls|         Men|    BRONZE|         Athlete|             NULL|https://olympics....|     Ikuma HORISHIMA|               Japan|          JP|                  JPN|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Hal...|         Men|      GOLD|         Athlete|             NULL|https://olympics....|       Nico PORTEOUS|         New Zealand|          NZ|                  NZL|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Hal...|         Men|    SILVER|         Athlete|             NULL|https://olympics....|          David WISE|United States of ...|          US|                  USA|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Hal...|         Men|    BRONZE|         Athlete|             NULL|https://olympics....|       Alex FERREIRA|United States of ...|          US|                  USA|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Big...|         Men|    BRONZE|         Athlete|             NULL|https://olympics....|      Henrik HARLAUT|              Sweden|          SE|                  SWE|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Big...|         Men|      GOLD|         Athlete|             NULL|https://olympics....|           Birk RUUD|              Norway|          NO|                  NOR|\n",
      "+----------------+------------+--------------------+------------+----------+----------------+-----------------+--------------------+--------------------+--------------------+------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_medal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- discipline_title: string (nullable = true)\n",
      " |-- game_slug: string (nullable = true)\n",
      " |-- event_title: string (nullable = true)\n",
      " |-- event_gender: string (nullable = true)\n",
      " |-- medal_type: string (nullable = true)\n",
      " |-- participant_type: string (nullable = true)\n",
      " |-- participant_title: string (nullable = true)\n",
      " |-- athlete_url: string (nullable = true)\n",
      " |-- athlete_full_name: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country_3_letter_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_medal.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21697"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_medal.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_medal=data_medal.drop(\"participant_title\")\n",
    "data_medal=data_medal.drop(\"athlete_url\")\n",
    "data_medal=data_medal.drop(\"country_name\")\n",
    "data_medal=data_medal.drop(\"country_code\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+--------------------+------------+----------+----------------+--------------------+---------------------+\n",
      "|discipline_title|   game_slug|         event_title|event_gender|medal_type|participant_type|   athlete_full_name|country_3_letter_code|\n",
      "+----------------+------------+--------------------+------------+----------+----------------+--------------------+---------------------+\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|      GOLD|        GameTeam|Stefania CONSTANTINI|                  ITA|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|      GOLD|        GameTeam|        Amos MOSANER|                  ITA|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|    SILVER|        GameTeam|    Kristin SKASLIEN|                  NOR|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|    SILVER|        GameTeam|  Magnus NEDREGOTTEN|                  NOR|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|    BRONZE|        GameTeam|       Almida DE VAL|                  SWE|\n",
      "|         Curling|beijing-2022|       Mixed Doubles|       Mixed|    BRONZE|        GameTeam|      Oskar ERIKSSON|                  SWE|\n",
      "|         Curling|beijing-2022|               Women|       Women|      GOLD|        GameTeam|                NULL|                  GBR|\n",
      "|         Curling|beijing-2022|               Women|       Women|    SILVER|        GameTeam|                NULL|                  JPN|\n",
      "|         Curling|beijing-2022|               Women|       Women|    BRONZE|        GameTeam|                NULL|                  SWE|\n",
      "|         Curling|beijing-2022|                 Men|         Men|      GOLD|        GameTeam|                NULL|                  SWE|\n",
      "|         Curling|beijing-2022|                 Men|         Men|    SILVER|        GameTeam|                NULL|                  GBR|\n",
      "|         Curling|beijing-2022|                 Men|         Men|    BRONZE|        GameTeam|                NULL|                  CAN|\n",
      "|Freestyle Skiing|beijing-2022|        Men's Moguls|         Men|    SILVER|         Athlete|    Mikael KINGSBURY|                  CAN|\n",
      "|Freestyle Skiing|beijing-2022|        Men's Moguls|         Men|      GOLD|         Athlete|     Walter WALLBERG|                  SWE|\n",
      "|Freestyle Skiing|beijing-2022|        Men's Moguls|         Men|    BRONZE|         Athlete|     Ikuma HORISHIMA|                  JPN|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Hal...|         Men|      GOLD|         Athlete|       Nico PORTEOUS|                  NZL|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Hal...|         Men|    SILVER|         Athlete|          David WISE|                  USA|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Hal...|         Men|    BRONZE|         Athlete|       Alex FERREIRA|                  USA|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Big...|         Men|    BRONZE|         Athlete|      Henrik HARLAUT|                  SWE|\n",
      "|Freestyle Skiing|beijing-2022|Men's Freeski Big...|         Men|      GOLD|         Athlete|           Birk RUUD|                  NOR|\n",
      "+----------------+------------+--------------------+------------+----------+----------------+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_medal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|country_3_letter_code|count|\n",
      "+---------------------+-----+\n",
      "|                  POL|  345|\n",
      "|                  BUR|    1|\n",
      "|                  JAM|   86|\n",
      "|                  BRA|  180|\n",
      "|                  ARM|   18|\n",
      "|                  MOZ|    2|\n",
      "|                  CUB|  239|\n",
      "|                  JOR|    3|\n",
      "|                  FRA|  952|\n",
      "|                  ALG|   17|\n",
      "|                  BRN|    4|\n",
      "|                  VIE|    4|\n",
      "|                  BOT|    2|\n",
      "|                  RSA|   95|\n",
      "|                  ETH|   57|\n",
      "|                  ITA|  805|\n",
      "|                  UKR|  159|\n",
      "|                  GHA|    5|\n",
      "|                  OAR|   18|\n",
      "|                  CMR|    6|\n",
      "|                  SCG|    9|\n",
      "|                  SEN|    1|\n",
      "|                  AHO|    1|\n",
      "|                  GUY|    1|\n",
      "|                  TOG|    1|\n",
      "|                  QAT|    9|\n",
      "|                  GUA|    1|\n",
      "|                  GBR| 1045|\n",
      "|                  TCH|  178|\n",
      "|                  FIJ|    3|\n",
      "|                  TJK|    4|\n",
      "|                  ERI|    1|\n",
      "|                  UGA|   11|\n",
      "|                  ZIM|    8|\n",
      "|                  AZE|   50|\n",
      "|                  AUS|  627|\n",
      "|                  PUR|   10|\n",
      "|                  MEX|   77|\n",
      "|                  PAR|    1|\n",
      "|                  AFG|    2|\n",
      "|                  SRI|    2|\n",
      "|                  SLO|   56|\n",
      "|                  TGA|    1|\n",
      "|                  GDR|  562|\n",
      "|                  SUD|    1|\n",
      "|                  BLR|  113|\n",
      "|                  SVK|   47|\n",
      "|                  NIG|    2|\n",
      "|                  HUN|  559|\n",
      "|                  TKM|    1|\n",
      "|                  NZL|  173|\n",
      "|                  MRI|    1|\n",
      "|                  THA|   35|\n",
      "|                  DJI|    1|\n",
      "|                  NOR|  589|\n",
      "|                  KOS|    3|\n",
      "|                  IRQ|    1|\n",
      "|                  VEN|   19|\n",
      "|                  FIN|  490|\n",
      "|                  POR|   33|\n",
      "|                  DEN|  233|\n",
      "|                  DOM|   12|\n",
      "|                  UAR|    2|\n",
      "|                  SUR|    2|\n",
      "|                  BAH|   18|\n",
      "|                  URU|   12|\n",
      "|                  NED|  501|\n",
      "|                  PER|    4|\n",
      "|                  PAK|   10|\n",
      "|                  EUN|  141|\n",
      "|                  LUX|    5|\n",
      "|                  TUR|  103|\n",
      "|                  IOA|    5|\n",
      "|                  MNE|    1|\n",
      "|                  AUT|  371|\n",
      "|                  BDI|    2|\n",
      "|                  USA| 3094|\n",
      "|                  MAR|   24|\n",
      "|                  GEO|   40|\n",
      "|                  PAN|    3|\n",
      "|                  CIV|    4|\n",
      "|                  KOR|  393|\n",
      "|                  PRK|   58|\n",
      "|                  LIE|   10|\n",
      "|                  GER| 1167|\n",
      "|                  ISR|   13|\n",
      "|                  TUN|   15|\n",
      "|                  NAM|    5|\n",
      "|                  SMR|    4|\n",
      "|                  LTU|   30|\n",
      "|                  CYP|    1|\n",
      "|                  YUG|   94|\n",
      "|                  UAE|    2|\n",
      "|                  CRC|    4|\n",
      "|                  BOH|    4|\n",
      "|                  CAN|  602|\n",
      "|                  MAS|   19|\n",
      "|                  SUI|  402|\n",
      "|                  COL|   34|\n",
      "|                  RUS|  599|\n",
      "+---------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_medal.groupBy(\"country_3_letter_code\").count().show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+------------------+-------------------+-----------+---------+\n",
      "|          game_slug|      game_end_date|    game_start_date|     game_location|          game_name|game_season|game_year|\n",
      "+-------------------+-------------------+-------------------+------------------+-------------------+-----------+---------+\n",
      "|       beijing-2022|2022-02-20 13:00:00|2022-02-04 16:00:00|             China|       Beijing 2022|     Winter|     2022|\n",
      "|         tokyo-2020|2021-08-08 16:00:00|2021-07-23 13:00:00|             Japan|         Tokyo 2020|     Summer|     2020|\n",
      "|   pyeongchang-2018|2018-02-25 09:00:00|2018-02-09 00:00:00| Republic of Korea|   PyeongChang 2018|     Winter|     2018|\n",
      "|           rio-2016|2016-08-21 23:00:00|2016-08-05 14:00:00|            Brazil|           Rio 2016|     Summer|     2016|\n",
      "|         sochi-2014|2014-02-23 17:00:00|2014-02-07 05:00:00|Russian Federation|         Sochi 2014|     Winter|     2014|\n",
      "|        london-2012|2012-08-12 21:00:00|2012-07-27 09:00:00|     Great Britain|        London 2012|     Summer|     2012|\n",
      "|     vancouver-2010|2010-02-28 05:00:00|2010-02-12 17:00:00|            Canada|     Vancouver 2010|     Winter|     2010|\n",
      "|       beijing-2008|2008-08-24 14:00:00|2008-08-08 02:00:00|             China|       Beijing 2008|     Summer|     2008|\n",
      "|         turin-2006|2006-02-26 20:00:00|2006-02-10 08:00:00|             Italy|         Turin 2006|     Winter|     2006|\n",
      "|        athens-2004|2004-08-29 20:00:00|2004-08-13 08:00:00|            Greece|        Athens 2004|     Summer|     2004|\n",
      "|salt-lake-city-2002|2002-02-24 09:00:00|2002-02-08 16:00:00|     United States|Salt Lake City 2002|     Winter|     2002|\n",
      "|        sydney-2000|2000-10-01 11:00:00|2000-09-15 03:00:00|         Australia|        Sydney 2000|     Summer|     2000|\n",
      "|        nagano-1998|1998-02-22 12:00:00|1998-02-07 00:00:00|             Japan|        Nagano 1998|     Winter|     1998|\n",
      "|       atlanta-1996|1996-08-05 23:00:00|1996-07-19 14:00:00|     United States|       Atlanta 1996|     Summer|     1996|\n",
      "|   lillehammer-1994|1994-02-27 20:00:00|1994-02-12 08:00:00|            Norway|   Lillehammer 1994|     Winter|     1994|\n",
      "|     barcelona-1992|1992-08-09 20:00:00|1992-07-25 08:00:00|             Spain|     Barcelona 1992|     Summer|     1992|\n",
      "|   albertville-1992|1992-02-23 20:00:00|1992-02-08 08:00:00|            France|   Albertville 1992|     Winter|     1992|\n",
      "|         seoul-1988|1988-10-02 11:00:00|1988-09-17 00:00:00| Republic of Korea|         Seoul 1988|     Summer|     1988|\n",
      "|       calgary-1988|1988-02-28 04:00:00|1988-02-13 16:00:00|            Canada|       Calgary 1988|     Winter|     1988|\n",
      "|   los-angeles-1984|1984-08-12 21:00:00|1984-07-28 17:00:00|     United States|   Los Angeles 1984|     Summer|     1984|\n",
      "+-------------------+-------------------+-------------------+------------------+-------------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_host.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- game_slug: string (nullable = true)\n",
      " |-- game_end_date: timestamp (nullable = true)\n",
      " |-- game_start_date: timestamp (nullable = true)\n",
      " |-- game_location: string (nullable = true)\n",
      " |-- game_name: string (nullable = true)\n",
      " |-- game_season: string (nullable = true)\n",
      " |-- game_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_host.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_host.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_host.write.csv(\"Clean_Data/cleaned_host.csv\", header=True, mode='overwrite')\n",
    "data_medal.write.csv(\"Clean_Data/cleaned_medal.csv\", header=True, mode='overwrite')\n",
    "data_athletes.write.csv(\"Clean_Data/cleaned_ahletes.csv\", header=True, mode='overwrite')\n",
    "data_result.write.csv(\"Clean_Data/cleaned_result.csv\", header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=data_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=final_data.join(data_host, on='game_slug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+-------------+----------------+----------+-------------+--------------------+---------------------+-------------------+-------------------+-------------+------------+-----------+---------+\n",
      "|   game_slug|discipline_title|  event_title|participant_type|medal_type|rank_position|        country_name|country_3_letter_code|      game_end_date|    game_start_date|game_location|   game_name|game_season|game_year|\n",
      "+------------+----------------+-------------+----------------+----------+-------------+--------------------+---------------------+-------------------+-------------------+-------------+------------+-----------+---------+\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|      GOLD|            1|               Italy|                  ITA|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|    SILVER|            2|              Norway|                  NOR|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|    BRONZE|            3|              Sweden|                  SWE|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|         0|            4|       Great Britain|                  GBR|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|         0|            5|              Canada|                  CAN|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|         0|            6|      Czech Republic|                  CZE|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|         0|            7|         Switzerland|                  SUI|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|         0|            8|United States of ...|                  USA|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|         0|            9|People's Republic...|                  CHN|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|Mixed Doubles|        GameTeam|         0|           10|           Australia|                  AUS|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|      GOLD|            1|       Great Britain|                  GBR|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|    SILVER|            2|               Japan|                  JPN|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|    BRONZE|            3|              Sweden|                  SWE|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|         0|            4|         Switzerland|                  SUI|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|         0|            5|              Canada|                  CAN|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|         0|            6|United States of ...|                  USA|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|         0|            7|People's Republic...|                  CHN|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|         0|            8|   Republic of Korea|                  KOR|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|         0|            9|             Denmark|                  DEN|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "|beijing-2022|         Curling|        Women|        GameTeam|         0|           10|                 ROC|                  ROC|2022-02-20 13:00:00|2022-02-04 16:00:00|        China|Beijing 2022|     Winter|     2022|\n",
      "+------------+----------------+-------------+----------------+----------+-------------+--------------------+---------------------+-------------------+-------------------+-------------+------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- game_slug: string (nullable = true)\n",
      " |-- game_end_date: timestamp (nullable = true)\n",
      " |-- game_start_date: timestamp (nullable = true)\n",
      " |-- game_location: string (nullable = true)\n",
      " |-- game_name: string (nullable = true)\n",
      " |-- game_season: string (nullable = true)\n",
      " |-- game_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_host.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=final_data.drop(\"game_end_date\")\n",
    "final_data=final_data.drop(\"game_start_date\")\n",
    "final_data=final_data.drop(\"game_name\")\n",
    "final_data=final_data.drop(\"game_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- game_slug: string (nullable = true)\n",
      " |-- discipline_title: string (nullable = true)\n",
      " |-- event_title: string (nullable = true)\n",
      " |-- participant_type: string (nullable = true)\n",
      " |-- medal_type: string (nullable = false)\n",
      " |-- rank_position: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- country_3_letter_code: string (nullable = true)\n",
      " |-- game_season: string (nullable = true)\n",
      " |-- game_year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.filter(final_data['game_season'] == 'Summer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117159"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+\n",
      "| game_slug|discipline_title|         event_title|participant_type|medal_type|rank_position|        country_name|country_3_letter_code|game_season|game_year|\n",
      "+----------+----------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|      GOLD|            1|               Spain|                  ESP|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|    SILVER|            2|          San Marino|                  SMR|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|    BRONZE|            3|United States of ...|                  USA|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            4|            Slovakia|                  SVK|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            5|               Japan|                  JPN|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            6|           Australia|                  AUS|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            7|           Australia|                  AUS|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            8|            Slovakia|                  SVK|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            9|People's Republic...|                  CHN|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           10|       Great Britain|                  GBR|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           11|                 ROC|                  ROC|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           12|               Italy|                  ITA|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           13|United States of ...|                  USA|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           14|                 ROC|                  ROC|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           15|              Mexico|                  MEX|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           16|               Egypt|                  EGY|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|50m Rifle 3 Posit...|         Athlete|         0|           19|People's Republic...|                  CHN|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|50m Rifle 3 Posit...|         Athlete|         0|            5|United States of ...|                  USA|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|50m Rifle 3 Posit...|         Athlete|         0|           17|             Belarus|                  BLR|     Summer|     2020|\n",
      "|tokyo-2020|        Shooting|50m Rifle 3 Posit...|         Athlete|    BRONZE|            3|                 ROC|                  ROC|     Summer|     2020|\n",
      "+----------+----------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.withColumn(\n",
    "    'm_total', when(col('medal_type') == 'None', 0).otherwise(1)\n",
    ").withColumn(\n",
    "    'm_gold', when(col('medal_type') == 'GOLD', 1).otherwise(0)\n",
    ").withColumn(\n",
    "    'm_silver', when(col('medal_type') == 'SILVER', 1).otherwise(0)\n",
    ").withColumn(\n",
    "    'm_bronze', when(col('medal_type') == 'BRONZE', 1).otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+-------+------+--------+--------+\n",
      "| game_slug|discipline_title|         event_title|participant_type|medal_type|rank_position|        country_name|country_3_letter_code|game_season|game_year|m_total|m_gold|m_silver|m_bronze|\n",
      "+----------+----------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+-------+------+--------+--------+\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|      GOLD|            1|               Spain|                  ESP|     Summer|     2020|      1|     1|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|    SILVER|            2|          San Marino|                  SMR|     Summer|     2020|      1|     0|       1|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|    BRONZE|            3|United States of ...|                  USA|     Summer|     2020|      1|     0|       0|       1|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            4|            Slovakia|                  SVK|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            5|               Japan|                  JPN|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            6|           Australia|                  AUS|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            7|           Australia|                  AUS|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            8|            Slovakia|                  SVK|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|            9|People's Republic...|                  CHN|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           10|       Great Britain|                  GBR|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           11|                 ROC|                  ROC|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           12|               Italy|                  ITA|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           13|United States of ...|                  USA|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           14|                 ROC|                  ROC|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           15|              Mexico|                  MEX|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|     Trap Mixed Team|        GameTeam|         0|           16|               Egypt|                  EGY|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|50m Rifle 3 Posit...|         Athlete|         0|           19|People's Republic...|                  CHN|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|50m Rifle 3 Posit...|         Athlete|         0|            5|United States of ...|                  USA|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|50m Rifle 3 Posit...|         Athlete|         0|           17|             Belarus|                  BLR|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Shooting|50m Rifle 3 Posit...|         Athlete|    BRONZE|            3|                 ROC|                  ROC|     Summer|     2020|      1|     0|       0|       1|\n",
      "+----------+----------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+-------+------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_no_duplicates = final_data.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+-------+------+--------+--------+\n",
      "| game_slug|    discipline_title|         event_title|participant_type|medal_type|rank_position|        country_name|country_3_letter_code|game_season|game_year|m_total|m_gold|m_silver|m_bronze|\n",
      "+----------+--------------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+-------+------+--------+--------+\n",
      "|tokyo-2020|              Diving|Men's Synchronise...|        GameTeam|    BRONZE|            3|             Germany|                  GER|     Summer|     2020|      1|     0|       0|       1|\n",
      "|tokyo-2020|              Diving|  Men's 10m Platform|         Athlete|         0|            9|United States of ...|                  USA|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Canoe Sprint|Men's Kayak Doubl...|        GameTeam|         0|            4|             Hungary|                  HUN|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Canoe Sprint|Men's Canoe Singl...|         Athlete|         0|            8|People's Republic...|                  CHN|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Cycling Road|   Women's Road Race|         Athlete|         0|          DNF|             Belgium|                  BEL|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Cycling Road|Men's Individual ...|         Athlete|         0|            5|               Italy|                  ITA|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|        Cycling Road|     Men's Road Race|         Athlete|         0|           29|             Germany|                  GER|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|            Football|                 Men|        GameTeam|         0|           13|              France|                  FRA|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|              Boxing|Men's Super Heavy...|         Athlete|    SILVER|            2|United States of ...|                  USA|     Summer|     2020|      1|     0|       1|       0|\n",
      "|tokyo-2020|              Boxing|Women's Light (57...|         Athlete|         0|            5|          Uzbekistan|                  UZB|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|              Boxing| Men's Fly (48-52kg)|         Athlete|         0|           17|            Botswana|                  BOT|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|   Marathon Swimming|          Men's 10km|         Athlete|         0|           23|            Portugal|                  POR|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|Trampoline Gymnas...|                 Men|         Athlete|      GOLD|            1|             Belarus|                  BLR|     Summer|     2020|      1|     1|       0|       0|\n",
      "|tokyo-2020|           Taekwondo|           Men -80kg|         Athlete|         0|           11|               Spain|                  ESP|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|       Cycling Track|        Men's Sprint|         Athlete|         0|           13|            Suriname|                  SUR|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|             Fencing|Women's pe In...|         Athlete|         0|            9|People's Republic...|                  CHN|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|             Fencing|   Women's Foil Team|        GameTeam|         0|            6|               Japan|                  JPN|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|           Badminton|       Men's Singles|         Athlete|         0|            5|      Chinese Taipei|                  TPE|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020|              Tennis|       Men's Singles|         Athlete|         0|           17|      Czech Republic|                  CZE|     Summer|     2020|      1|     0|       0|       0|\n",
      "|tokyo-2020| Artistic Gymnastics|    Men's All-Around|         Athlete|         0|           11|             Ukraine|                  UKR|     Summer|     2020|      1|     0|       0|       0|\n",
      "+----------+--------------------+--------------------+----------------+----------+-------------+--------------------+---------------------+-----------+---------+-------+------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_data_no_duplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117159"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "112529"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_no_duplicates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_no_duplicates=final_data_no_duplicates.drop(\"country_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Final_data_df=final_data_no_duplicates.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data_df.to_csv(\"Dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_slug</th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>event_title</th>\n",
       "      <th>participant_type</th>\n",
       "      <th>medal_type</th>\n",
       "      <th>rank_position</th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "      <th>game_season</th>\n",
       "      <th>game_year</th>\n",
       "      <th>m_total</th>\n",
       "      <th>m_gold</th>\n",
       "      <th>m_silver</th>\n",
       "      <th>m_bronze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tokyo-2020</td>\n",
       "      <td>Diving</td>\n",
       "      <td>Men's Synchronised 3m Springboard</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>BRONZE</td>\n",
       "      <td>3</td>\n",
       "      <td>Germany</td>\n",
       "      <td>GER</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokyo-2020</td>\n",
       "      <td>Diving</td>\n",
       "      <td>Men's 10m Platform</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USA</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokyo-2020</td>\n",
       "      <td>Canoe Sprint</td>\n",
       "      <td>Men's Kayak Double 1000m</td>\n",
       "      <td>GameTeam</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>HUN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tokyo-2020</td>\n",
       "      <td>Canoe Sprint</td>\n",
       "      <td>Men's Canoe Single 1000m</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>People's Republic of China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tokyo-2020</td>\n",
       "      <td>Cycling Road</td>\n",
       "      <td>Women's Road Race</td>\n",
       "      <td>Athlete</td>\n",
       "      <td>0</td>\n",
       "      <td>DNF</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>BEL</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    game_slug discipline_title                        event_title  \\\n",
       "0  tokyo-2020           Diving  Men's Synchronised 3m Springboard   \n",
       "1  tokyo-2020           Diving                 Men's 10m Platform   \n",
       "2  tokyo-2020     Canoe Sprint           Men's Kayak Double 1000m   \n",
       "3  tokyo-2020     Canoe Sprint           Men's Canoe Single 1000m   \n",
       "4  tokyo-2020     Cycling Road                  Women's Road Race   \n",
       "\n",
       "  participant_type medal_type rank_position                country_name  \\\n",
       "0         GameTeam     BRONZE             3                     Germany   \n",
       "1          Athlete          0             9    United States of America   \n",
       "2         GameTeam          0             4                     Hungary   \n",
       "3          Athlete          0             8  People's Republic of China   \n",
       "4          Athlete          0           DNF                     Belgium   \n",
       "\n",
       "  country_3_letter_code game_season  game_year  m_total  m_gold  m_silver  \\\n",
       "0                   GER      Summer       2020        1       0         0   \n",
       "1                   USA      Summer       2020        1       0         0   \n",
       "2                   HUN      Summer       2020        1       0         0   \n",
       "3                   CHN      Summer       2020        1       0         0   \n",
       "4                   BEL      Summer       2020        1       0         0   \n",
       "\n",
       "   m_bronze  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prparation de donnes pour la Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data_df['m_total'] = pd.to_numeric(Final_data_df['m_total'], errors='coerce').fillna(0)\n",
    "Final_data_df['m_gold'] = pd.to_numeric(Final_data_df['m_gold'], errors='coerce').fillna(0)\n",
    "Final_data_df['m_silver'] = pd.to_numeric(Final_data_df['m_silver'], errors='coerce').fillna(0)\n",
    "Final_data_df['m_bronze'] = pd.to_numeric(Final_data_df['m_bronze'], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crer un DataFrame agrg par anne et par pays pour le nombre total de mdailles\n",
    "agg_df = Final_data_df.groupby(['game_year', 'country_name'])['m_total'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation pour avoir les annes en colonnes (features) et les pays en lignes (instances)\n",
    "pivot_df = agg_df.pivot(index='country_name', columns='game_year', values='m_total').fillna(0)\n",
    "pivot_df = pivot_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_year\n",
      "country_name     object\n",
      "1896            float64\n",
      "1900            float64\n",
      "1904            float64\n",
      "1908            float64\n",
      "1912            float64\n",
      "1920            float64\n",
      "1924            float64\n",
      "1928            float64\n",
      "1932            float64\n",
      "1936            float64\n",
      "1948            float64\n",
      "1952            float64\n",
      "1956            float64\n",
      "1960            float64\n",
      "1964            float64\n",
      "1968            float64\n",
      "1972            float64\n",
      "1976            float64\n",
      "1980            float64\n",
      "1984            float64\n",
      "1988            float64\n",
      "1992            float64\n",
      "1996            float64\n",
      "2000            float64\n",
      "2004            float64\n",
      "2008            float64\n",
      "2012            float64\n",
      "2016            float64\n",
      "2020            float64\n",
      "dtype: object\n",
      "game_year\n",
      "country_name    0\n",
      "1896            0\n",
      "1900            0\n",
      "1904            0\n",
      "1908            0\n",
      "1912            0\n",
      "1920            0\n",
      "1924            0\n",
      "1928            0\n",
      "1932            0\n",
      "1936            0\n",
      "1948            0\n",
      "1952            0\n",
      "1956            0\n",
      "1960            0\n",
      "1964            0\n",
      "1968            0\n",
      "1972            0\n",
      "1976            0\n",
      "1980            0\n",
      "1984            0\n",
      "1988            0\n",
      "1992            0\n",
      "1996            0\n",
      "2000            0\n",
      "2004            0\n",
      "2008            0\n",
      "2012            0\n",
      "2016            0\n",
      "2020            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vrifier le type de donnes dans pivot_df\n",
    "print(pivot_df.dtypes)\n",
    "\n",
    "# Vrifier s'il y a des valeurs non numriques ou manquantes dans pivot_df\n",
    "print(pivot_df.isna().sum())\n",
    "\n",
    "# Si ncessaire, nettoyer les donnes\n",
    "pivot_df = pivot_df.fillna(0)  # Remplacer les valeurs manquantes par 0\n",
    "pivot_df = pivot_df.apply(pd.to_numeric, errors='coerce')  # Convertir toutes les colonnes en numriques\n",
    "\n",
    "# Ressayer de calculer la somme totale des mdailles\n",
    "y = pivot_df.sum(axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pivot_df.drop(columns=['country_name']).values\n",
    "y = pivot_df.sum(axis=1).values  # Somme totale des mdailles comme variable cible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les donnes en ensemble d'entranement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialiser le modle de rgression linaire\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraner le modle\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prdictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique moyenne (MSE) : 1.7850391626065514e-25\n",
      "Coefficient de dtermination (R) : 1.0\n"
     ]
    }
   ],
   "source": [
    "# valuer le modle\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Erreur quadratique moyenne (MSE) : {mse}\")\n",
    "print(f\"Coefficient de dtermination (R) : {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slection des caractristiques pertinentes\n",
    "features = ['discipline_title', 'country_3_letter_code', 'game_season', 'game_year']\n",
    "X = Final_data_df[features]\n",
    "y = Final_data_df['medal_type']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discipline_title</th>\n",
       "      <th>country_3_letter_code</th>\n",
       "      <th>game_season</th>\n",
       "      <th>game_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diving</td>\n",
       "      <td>GER</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diving</td>\n",
       "      <td>USA</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canoe Sprint</td>\n",
       "      <td>HUN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canoe Sprint</td>\n",
       "      <td>CHN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cycling Road</td>\n",
       "      <td>BEL</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112524</th>\n",
       "      <td>Gymnastics Artistic</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112525</th>\n",
       "      <td>Athletics</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112526</th>\n",
       "      <td>Athletics</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112527</th>\n",
       "      <td>Cycling Track</td>\n",
       "      <td>GER</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112528</th>\n",
       "      <td>Equestrian Jumping</td>\n",
       "      <td>FRA</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112529 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           discipline_title country_3_letter_code game_season  game_year\n",
       "0                    Diving                   GER      Summer       2020\n",
       "1                    Diving                   USA      Summer       2020\n",
       "2              Canoe Sprint                   HUN      Summer       2020\n",
       "3              Canoe Sprint                   CHN      Summer       2020\n",
       "4              Cycling Road                   BEL      Summer       2020\n",
       "...                     ...                   ...         ...        ...\n",
       "112524  Gymnastics Artistic                   FRA      Summer       1900\n",
       "112525            Athletics                   GBR      Summer       1896\n",
       "112526            Athletics                   FRA      Summer       1896\n",
       "112527        Cycling Track                   GER      Summer       1896\n",
       "112528   Equestrian Jumping                   FRA      Summer       1976\n",
       "\n",
       "[112529 rows x 4 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   game_year  discipline_title_3x3 Basketball  discipline_title_Archery  \\\n",
      "0       2020                            False                     False   \n",
      "1       2020                            False                     False   \n",
      "2       2020                            False                     False   \n",
      "3       2020                            False                     False   \n",
      "4       2020                            False                     False   \n",
      "\n",
      "   discipline_title_Artistic Gymnastics  discipline_title_Artistic Swimming  \\\n",
      "0                                 False                               False   \n",
      "1                                 False                               False   \n",
      "2                                 False                               False   \n",
      "3                                 False                               False   \n",
      "4                                 False                               False   \n",
      "\n",
      "   discipline_title_Athletics  discipline_title_Badminton  \\\n",
      "0                       False                       False   \n",
      "1                       False                       False   \n",
      "2                       False                       False   \n",
      "3                       False                       False   \n",
      "4                       False                       False   \n",
      "\n",
      "   discipline_title_Baseball  discipline_title_Baseball/Softball  \\\n",
      "0                      False                               False   \n",
      "1                      False                               False   \n",
      "2                      False                               False   \n",
      "3                      False                               False   \n",
      "4                      False                               False   \n",
      "\n",
      "   discipline_title_Basketball  ...  country_3_letter_code_VEN  \\\n",
      "0                        False  ...                      False   \n",
      "1                        False  ...                      False   \n",
      "2                        False  ...                      False   \n",
      "3                        False  ...                      False   \n",
      "4                        False  ...                      False   \n",
      "\n",
      "   country_3_letter_code_VIE  country_3_letter_code_VIN  \\\n",
      "0                      False                      False   \n",
      "1                      False                      False   \n",
      "2                      False                      False   \n",
      "3                      False                      False   \n",
      "4                      False                      False   \n",
      "\n",
      "   country_3_letter_code_YAR  country_3_letter_code_YEM  \\\n",
      "0                      False                      False   \n",
      "1                      False                      False   \n",
      "2                      False                      False   \n",
      "3                      False                      False   \n",
      "4                      False                      False   \n",
      "\n",
      "   country_3_letter_code_YMD  country_3_letter_code_YUG  \\\n",
      "0                      False                      False   \n",
      "1                      False                      False   \n",
      "2                      False                      False   \n",
      "3                      False                      False   \n",
      "4                      False                      False   \n",
      "\n",
      "   country_3_letter_code_ZAM  country_3_letter_code_ZIM  game_season_Summer  \n",
      "0                      False                      False                True  \n",
      "1                      False                      False                True  \n",
      "2                      False                      False                True  \n",
      "3                      False                      False                True  \n",
      "4                      False                      False                True  \n",
      "\n",
      "[5 rows x 288 columns]\n"
     ]
    }
   ],
   "source": [
    "# Utiliser l'encodage one-hot pour convertir les caractristiques catgoriques en variables binaires\n",
    "X_encoded = pd.get_dummies(X, columns=['discipline_title', 'country_3_letter_code', 'game_season'])\n",
    "\n",
    "# Afficher les donnes aprs l'encodage\n",
    "print(X_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraner le modle de rgression logistique\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8543499511241447\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for France: ['0' '0' '0' ... '0' '0' '0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/30 18:33:57 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 971018 ms exceeds timeout 120000 ms\n",
      "24/05/30 18:33:58 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "24/05/30 18:34:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:34:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:34:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:34:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:35:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:35:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:35:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:35:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:35:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:35:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:35:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:35:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:35:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:35:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:35:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:35:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:36:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:36:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:36:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:36:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:36:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:36:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:36:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:36:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:36:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:36:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:36:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:36:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:37:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:38:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:38:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:39:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:39:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:40:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:41:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:42:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:43:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/05/30 18:43:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.188.207.191:63878\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/05/30 18:43:52 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# Rechercher la colonne correspondant  la France dans X_encoded\n",
    "france_column = 'country_3_letter_code_FRA'  # Remplacez 'FRA' par le code correspondant  la France dans votre encodage\n",
    "\n",
    "# Slectionner les lignes o la France est prsente en utilisant la colonne correspondante\n",
    "france_data = X_encoded[X_encoded[france_column] == 1]\n",
    "\n",
    "# Effectuer la prdiction pour la France\n",
    "prediction = model.predict(france_data)\n",
    "print(\"Prediction for France:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'country_3_letter_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'country_3_letter_code'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m france_data \u001b[38;5;241m=\u001b[39m X_encoded[\u001b[43mX_encoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcountry_3_letter_code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(france_data)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction for France:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'country_3_letter_code'"
     ]
    }
   ],
   "source": [
    "france_data = X_encoded[X_encoded['country_3_letter_code'] == 1]\n",
    "prediction = model.predict(france_data)\n",
    "print(\"Prediction for France:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rpartition des mdailles par type (or, argent, bronze) pour les top 10 pays :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_10_countries = Final_data_df.groupby('country_name')['m_total'].sum().nlargest(10).index\n",
    "top_10_data = Final_data_df[Final_data_df['country_name'].isin(top_10_countries)]\n",
    "\n",
    "top_10_medals = top_10_data.groupby('country_name')[['m_gold', 'm_silver', 'm_bronze']].sum().reset_index()\n",
    "\n",
    "top_10_medals.plot(kind='bar', x='country_name', stacked=True, figsize=(12, 8), color=['gold', 'silver', '#cd7f32'])\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Number of Medals')\n",
    "plt.title('Medal Distribution by Type for Top 10 Countries')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "volution du nombre total de mdailles au fil des annes pour les top 5 pays :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_5_countries = Final_data_df.groupby('country_name')['m_total'].sum().nlargest(5).index\n",
    "top_5_data = Final_data_df[Final_data_df['country_name'].isin(top_5_countries)]\n",
    "\n",
    "evolution_medals = top_5_data.pivot_table(index='game_year', columns='country_name', values='m_total', aggfunc='sum').fillna(0)\n",
    "evolution_medals.plot(kind='line', figsize=(12, 8), marker='o')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Medals')\n",
    "plt.title('Evolution of Total Medals Over Years for Top 5 Countries')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
